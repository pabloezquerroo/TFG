{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloezquerroo/TFG/blob/main/YoloDarknet/YOLOv4_Darknet_Roboflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNVU7eu9CQj3"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf) for training on your own dataset.\n",
        "\n",
        "We also recommend reading our blog post on [Training YOLOv4 on custom data](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) side by side.\n",
        "\n",
        "We will take the following steps to implement YOLOv4 on our custom data:\n",
        "* Configure our GPU environment on Google Colab\n",
        "* Install the Darknet YOLOv4 training environment\n",
        "* Download our custom dataset for YOLOv4 and set up directories\n",
        "* Configure a custom YOLOv4 training config file for Darknet\n",
        "* Train our custom YOLOv4 object detector\n",
        "* Reload YOLOv4 trained weights and make inference on test images\n",
        "\n",
        "When you are done you will have a custom detector that you can use. It will make inference like this:\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/L0n564N.png)\n",
        "\n",
        "### **Reach out for support**\n",
        "\n",
        "If you run into any hurdles on your own data set or just want to share some cool results in your own domain, [reach out!](https://roboflow.ai)\n",
        "\n",
        "\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "# Configuring cuDNN on Colab for YOLOv4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bguKWgtxSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1fe997-609f-4b0f-858a-c8b93a41e368"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJYM7-_Had0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f1cac2-1c5e-44d5-9994-ba26af4a6586"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar  5 19:10:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_qFPIBgvlkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88be11b5-f5e1-4f2d-91f2-7bc1a4bcb552"
      },
      "source": [
        "# This cell ensures you have the correct architecture for your respective GPU\n",
        "# If you command is not found, look through these GPUs, find the respective\n",
        "# GPU and add them to the archTypes dictionary\n",
        "\n",
        "# Tesla V100\n",
        "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "\n",
        "# Tesla K80\n",
        "# ARCH= -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
        "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
        "\n",
        "# Jetson XAVIER\n",
        "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
        "\n",
        "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
        "# ARCH= -gencode arch=compute_61,code=sm_61\n",
        "\n",
        "# GP100/Tesla P100 - DGX-1\n",
        "# ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
        "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
        "\n",
        "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
        "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "\n",
        "      }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Type: Tesla T4\n",
            "\n",
            "ARCH Value: -gencode arch=compute_75,code=[sm_75,compute_75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3nkYzWwMuBk"
      },
      "source": [
        "## STEP 1. Install cuDNN according to the current CUDA version\n",
        "Colab added cuDNN as an inherent install - so you don't have to do a thing - major win\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "# Step 2: Installing Darknet for YOLOv4 on Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9uY-38P93oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b8ff76-f718-43f5-9f1c-9ccccce275db"
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf darknet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEktcfj9y9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5380f637-eddf-4bc5-d467-f4289af9fb99"
      },
      "source": [
        "#we clone the fork of darknet maintained by roboflow\n",
        "#small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/roboflow-ai/darknet.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 13289, done.\u001b[K\n",
            "remote: Total 13289 (delta 0), reused 0 (delta 0), pack-reused 13289\u001b[K\n",
            "Receiving objects: 100% (13289/13289), 12.17 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (9047/9047), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modificamos el archivo convolutional_layer.c"
      ],
      "metadata": {
        "id": "uJfQtTBN51sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PABLO\n",
        "%cd /content/darknet/src\n",
        "%rm convolutional_layer.c"
      ],
      "metadata": {
        "id": "PYAgXtVb5PKZ",
        "outputId": "4b10e7f7-d6d1-434b-a8d2-37da26de46f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PABLO\n",
        "%%writefile convolutional_layer.c\n",
        "#include \"convolutional_layer.h\"\n",
        "#include \"utils.h\"\n",
        "#include \"batchnorm_layer.h\"\n",
        "#include \"im2col.h\"\n",
        "#include \"col2im.h\"\n",
        "#include \"blas.h\"\n",
        "#include \"gemm.h\"\n",
        "#include \"box.h\"\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "#ifdef AI2\n",
        "#include \"xnor_layer.h\"\n",
        "#endif\n",
        "\n",
        "#ifdef __cplusplus\n",
        "#define PUT_IN_REGISTER\n",
        "#else\n",
        "#define PUT_IN_REGISTER register\n",
        "#endif\n",
        "\n",
        "#ifndef AI2\n",
        "#define AI2 0\n",
        "void forward_xnor_layer(layer l, network_state state);\n",
        "#endif\n",
        "\n",
        "void swap_binary(convolutional_layer *l)\n",
        "{\n",
        "    float *swap = l->weights;\n",
        "    l->weights = l->binary_weights;\n",
        "    l->binary_weights = swap;\n",
        "\n",
        "    #ifdef GPU\n",
        "    swap = l->weights_gpu;\n",
        "    l->weights_gpu = l->binary_weights_gpu;\n",
        "    l->binary_weights_gpu = swap;\n",
        "    #endif\n",
        "}\n",
        "\n",
        "void binarize_weights(float *weights, int n, int size, float *binary)\n",
        "{\n",
        "    int i, f;\n",
        "    for(f = 0; f < n; ++f){\n",
        "        float mean = 0;\n",
        "        for(i = 0; i < size; ++i){\n",
        "            mean += fabs(weights[f*size + i]);\n",
        "        }\n",
        "        mean = mean / size;\n",
        "        for(i = 0; i < size; ++i){\n",
        "            binary[f*size + i] = (weights[f*size + i] > 0) ? mean: -mean;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void binarize_cpu(float *input, int n, float *binary)\n",
        "{\n",
        "    int i;\n",
        "    for(i = 0; i < n; ++i){\n",
        "        binary[i] = (input[i] > 0) ? 1 : -1;\n",
        "    }\n",
        "}\n",
        "\n",
        "void binarize_input(float *input, int n, int size, float *binary)\n",
        "{\n",
        "    int i, s;\n",
        "    for(s = 0; s < size; ++s){\n",
        "        float mean = 0;\n",
        "        for(i = 0; i < n; ++i){\n",
        "            mean += fabs(input[i*size + s]);\n",
        "        }\n",
        "        mean = mean / n;\n",
        "        for(i = 0; i < n; ++i){\n",
        "            binary[i*size + s] = (input[i*size + s] > 0) ? mean : -mean;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int convolutional_out_height(convolutional_layer l)\n",
        "{\n",
        "    return (l.h + 2*l.pad - l.size) / l.stride_y + 1;\n",
        "}\n",
        "\n",
        "int convolutional_out_width(convolutional_layer l)\n",
        "{\n",
        "    return (l.w + 2*l.pad - l.size) / l.stride_x + 1;\n",
        "}\n",
        "\n",
        "image get_convolutional_image(convolutional_layer l)\n",
        "{\n",
        "    int h,w,c;\n",
        "    h = convolutional_out_height(l);\n",
        "    w = convolutional_out_width(l);\n",
        "    c = l.n;\n",
        "    return float_to_image(w,h,c,l.output);\n",
        "}\n",
        "\n",
        "image get_convolutional_delta(convolutional_layer l)\n",
        "{\n",
        "    int h,w,c;\n",
        "    h = convolutional_out_height(l);\n",
        "    w = convolutional_out_width(l);\n",
        "    c = l.n;\n",
        "    return float_to_image(w,h,c,l.delta);\n",
        "}\n",
        "\n",
        "size_t get_workspace_size32(layer l){\n",
        "#ifdef CUDNN\n",
        "    if(gpu_index >= 0){\n",
        "        size_t most = 0;\n",
        "        size_t s = 0;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle(),\n",
        "                l.srcTensorDesc,\n",
        "                l.weightDesc,\n",
        "                l.convDesc,\n",
        "                l.dstTensorDesc,\n",
        "                l.fw_algo,\n",
        "                &s));\n",
        "        if (s > most) most = s;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionBackwardFilterWorkspaceSize(cudnn_handle(),\n",
        "                l.srcTensorDesc,\n",
        "                l.ddstTensorDesc,\n",
        "                l.convDesc,\n",
        "                l.dweightDesc,\n",
        "                l.bf_algo,\n",
        "                &s));\n",
        "        if (s > most && l.train) most = s;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionBackwardDataWorkspaceSize(cudnn_handle(),\n",
        "                l.weightDesc,\n",
        "                l.ddstTensorDesc,\n",
        "                l.convDesc,\n",
        "                l.dsrcTensorDesc,\n",
        "                l.bd_algo,\n",
        "                &s));\n",
        "        if (s > most && l.train) most = s;\n",
        "        return most;\n",
        "    }\n",
        "    #endif\n",
        "    if (l.xnor) {\n",
        "        size_t re_packed_input_size = l.c * l.w * l.h * sizeof(float);\n",
        "        size_t workspace_size = (size_t)l.bit_align*l.size*l.size*l.c * sizeof(float);\n",
        "        if (workspace_size < re_packed_input_size) workspace_size = re_packed_input_size;\n",
        "        return workspace_size;\n",
        "    }\n",
        "    return (size_t)l.out_h*l.out_w*l.size*l.size*(l.c / l.groups)*sizeof(float);\n",
        "}\n",
        "\n",
        "size_t get_workspace_size16(layer l) {\n",
        "#if defined(CUDNN) && defined(CUDNN_HALF)\n",
        "    if (gpu_index >= 0) {\n",
        "        size_t most = 0;\n",
        "        size_t s = 0;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle(),\n",
        "            l.srcTensorDesc16,\n",
        "            l.weightDesc16,\n",
        "            l.convDesc,\n",
        "            l.dstTensorDesc16,\n",
        "            l.fw_algo16,\n",
        "            &s));\n",
        "        if (s > most) most = s;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionBackwardFilterWorkspaceSize(cudnn_handle(),\n",
        "            l.srcTensorDesc16,\n",
        "            l.ddstTensorDesc16,\n",
        "            l.convDesc,\n",
        "            l.dweightDesc16,\n",
        "            l.bf_algo16,\n",
        "            &s));\n",
        "        if (s > most && l.train) most = s;\n",
        "        CHECK_CUDNN(cudnnGetConvolutionBackwardDataWorkspaceSize(cudnn_handle(),\n",
        "            l.weightDesc16,\n",
        "            l.ddstTensorDesc16,\n",
        "            l.convDesc,\n",
        "            l.dsrcTensorDesc16,\n",
        "            l.bd_algo16,\n",
        "            &s));\n",
        "        if (s > most && l.train) most = s;\n",
        "        return most;\n",
        "    }\n",
        "#endif\n",
        "    return 0;\n",
        "    //if (l.xnor) return (size_t)l.bit_align*l.size*l.size*l.c * sizeof(float);\n",
        "    //return (size_t)l.out_h*l.out_w*l.size*l.size*l.c * sizeof(float);\n",
        "}\n",
        "\n",
        "size_t get_convolutional_workspace_size(layer l) {\n",
        "    size_t workspace_size = get_workspace_size32(l);\n",
        "    size_t workspace_size16 = get_workspace_size16(l);\n",
        "    if (workspace_size16 > workspace_size) workspace_size = workspace_size16;\n",
        "    return workspace_size;\n",
        "}\n",
        "#ifdef GPU\n",
        "#ifdef CUDNN\n",
        "void create_convolutional_cudnn_tensors(layer *l)\n",
        "{\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->normTensorDesc));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->normDstTensorDesc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->srcTensorDesc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->dstTensorDesc));\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&l->weightDesc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->dsrcTensorDesc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->ddstTensorDesc));\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&l->dweightDesc));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->normDstTensorDescF16));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->srcTensorDesc16));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->dstTensorDesc16));\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&l->weightDesc16));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->dsrcTensorDesc16));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&l->ddstTensorDesc16));\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&l->dweightDesc16));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateConvolutionDescriptor(&l->convDesc));\n",
        "}\n",
        "\n",
        "void cudnn_convolutional_setup(layer *l, int cudnn_preference, size_t workspace_size_specify)\n",
        "{\n",
        "\n",
        "// CUDNN_HALF\n",
        "    // TRUE_HALF_CONFIG is only supported on architectures with true fp16 support (compute capability 5.3 and 6.0):\n",
        "    //   Tegra X1, Jetson TX1, DRIVE CX, DRIVE PX, Quadro GP100, Tesla P100\n",
        "    // PSEUDO_HALF_CONFIG is required for Tensor Cores - our case!\n",
        "\n",
        "    cudnnDataType_t data_type = CUDNN_DATA_FLOAT;\n",
        "\n",
        "#if(CUDNN_MAJOR >= 7)\n",
        "    // Tensor Core uses CUDNN_TENSOR_OP_MATH instead of CUDNN_DEFAULT_MATH\n",
        "    // For *_ALGO_WINOGRAD_NONFUSED can be used CUDNN_DATA_FLOAT\n",
        "    // otherwise Input, Filter and Output descriptors (xDesc, yDesc, wDesc, dxDesc, dyDesc and dwDesc as applicable) have dataType = CUDNN_DATA_HALF\n",
        "    // Three techniques for training using Mixed-precision: https://devblogs.nvidia.com/mixed-precision-training-deep-neural-networks/\n",
        "    // 1. Accumulation into FP32\n",
        "    // 2. Loss Scaling - required only for: activation gradients. We do not use.\n",
        "    // 3. FP32 Master Copy of Weights\n",
        "    // More: http://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#tensor_ops\n",
        "    if (l->groups < 1) l->groups = 1;\n",
        "    if (l->stride_x < 1) l->stride_x = 1;\n",
        "    if (l->stride_y < 1) l->stride_y = 1;\n",
        "    CHECK_CUDNN(cudnnSetConvolutionGroupCount(l->convDesc, l->groups));\n",
        "    CHECK_CUDNN(cudnnSetConvolutionMathType(l->convDesc, CUDNN_TENSOR_OP_MATH));\n",
        "#if((CUDNN_MAJOR*10 + CUDNN_MINOR) >= 72)   // cuDNN >= 7.2\n",
        "    //CHECK_CUDNN(cudnnSetConvolutionMathType(l->convDesc, CUDNN_TENSOR_OP_MATH_ALLOW_CONVERSION)); // reduces the speed of regular and group convolution\n",
        "#endif\n",
        "#else   //if(CUDNN_MAJOR >= 7)\n",
        "    if (l->groups > 1) {\n",
        "        error(\"CUDNN < 7 doesn't support groups, please upgrade!\");\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    // INT8_CONFIG, INT8_EXT_CONFIG, INT8x4_CONFIG and INT8x4_EXT_CONFIG are only supported\n",
        "    //   on architectures with DP4A support (compute capability 6.1 and later).\n",
        "    //cudnnDataType_t data_type = CUDNN_DATA_INT8;\n",
        "\n",
        "    // backward delta\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->dsrcTensorDesc, CUDNN_TENSOR_NCHW, data_type, l->batch, l->c, l->h, l->w));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->ddstTensorDesc, CUDNN_TENSOR_NCHW, data_type, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(l->dweightDesc, data_type, CUDNN_TENSOR_NCHW, l->n, l->c / l->groups, l->size, l->size));\n",
        "\n",
        "    // forward\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->srcTensorDesc, CUDNN_TENSOR_NCHW, data_type, l->batch, l->c, l->h, l->w));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->dstTensorDesc, CUDNN_TENSOR_NCHW, data_type, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(l->weightDesc, data_type, CUDNN_TENSOR_NCHW, l->n, l->c / l->groups, l->size, l->size));\n",
        "\n",
        "    // backward delta\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->dsrcTensorDesc16, CUDNN_TENSOR_NCHW, CUDNN_DATA_HALF, l->batch, l->c, l->h, l->w));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->ddstTensorDesc16, CUDNN_TENSOR_NCHW, CUDNN_DATA_HALF, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(l->dweightDesc16, CUDNN_DATA_HALF, CUDNN_TENSOR_NCHW, l->n, l->c / l->groups, l->size, l->size));\n",
        "\n",
        "    // forward\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->srcTensorDesc16, CUDNN_TENSOR_NCHW, CUDNN_DATA_HALF, l->batch, l->c, l->h, l->w));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->dstTensorDesc16, CUDNN_TENSOR_NCHW, CUDNN_DATA_HALF, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(l->weightDesc16, CUDNN_DATA_HALF, CUDNN_TENSOR_NCHW, l->n, l->c / l->groups, l->size, l->size));\n",
        "\n",
        "    // batch norm\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->normDstTensorDescF16, CUDNN_TENSOR_NCHW, CUDNN_DATA_HALF, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "\n",
        "    // batch norm\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->normTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 1, l->out_c, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(l->normDstTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, l->batch, l->out_c, l->out_h, l->out_w));\n",
        "\n",
        "    //printf(\"\\n l->dilation = %d, l->pad = %d, l->size = %d, l->stride = %d, l->stride_x = %d, l->stride_y = %d, l->groups = %d, l->w = %d, l->h = %d, l->c = %d, l->n = %d, l->out_w = %d, l->out_h = %d, l->out_c = %d, l->batch = %d, data_type = %d \\n\",\n",
        "    //    l->dilation, l->pad, l->size, l->stride, l->stride_x, l->stride_y, l->groups, l->w, l->h, l->c, l->n, l->out_w, l->out_h, l->out_c, l->batch, data_type);\n",
        "#if(CUDNN_MAJOR >= 6)\n",
        "    CHECK_CUDNN(cudnnSetConvolution2dDescriptor(l->convDesc, l->pad * l->dilation, l->pad * l->dilation, l->stride_y, l->stride_x, l->dilation, l->dilation, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));    // cudnn >= 6.0\n",
        "#else\n",
        "    CHECK_CUDNN(cudnnSetConvolution2dDescriptor(l->convDesc, l->pad * l->dilation, l->pad * l->dilation, l->stride_y, l->stride_x, l->dilation, l->dilation, CUDNN_CROSS_CORRELATION));    // cudnn 5.1\n",
        "#endif\n",
        "    // int forward_algo = CUDNN_CONVOLUTION_FWD_PREFER_FASTEST; PABLO\n",
        "    int forward_algo = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3;\n",
        "    // int backward_algo = CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST; PABLO\n",
        "    int backward_algo = CUDNN_CONVOLUTION_BWD_DATA_ALGO_FFT;\n",
        "    // int backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST; PABLO\n",
        "    int backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_FFT;\n",
        "    if (cudnn_preference == cudnn_smallest)\n",
        "    {\n",
        "        // forward_algo = CUDNN_CONVOLUTION_FWD_NO_WORKSPACE; PABLO\n",
        "        forward_algo = CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD;\n",
        "        // backward_algo = CUDNN_CONVOLUTION_BWD_DATA_NO_WORKSPACE; PABLO\n",
        "        backward_algo = CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD;\n",
        "        // backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_NO_WORKSPACE; PABLO\n",
        "        backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD;\n",
        "        printf(\" CUDNN-slow \");\n",
        "    }\n",
        "    if (cudnn_preference == cudnn_specify)\n",
        "    {\n",
        "        // forward_algo = CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT; PABLO\n",
        "        forward_algo = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3;\n",
        "        // backward_algo = CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT; PABLO\n",
        "        backward_algo = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3;\n",
        "        // backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT; PABLO\n",
        "        backward_filter = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_3;\n",
        "        //printf(\" CUDNN-specified %zu \", workspace_size_specify);\n",
        "    }\n",
        "\n",
        "    // CHECK_CUDNN(cudnnGetConvolutionForwardAlgorithm(cudnn_handle(),\n",
        "    //         l->srcTensorDesc,\n",
        "    //         l->weightDesc,\n",
        "    //         l->convDesc,\n",
        "    //         l->dstTensorDesc,\n",
        "    //         (cudnnConvolutionFwdPreference_t)forward_algo,\n",
        "    //         workspace_size_specify,\n",
        "    //         &l->fw_algo));\n",
        "    // CHECK_CUDNN(cudnnGetConvolutionBackwardDataAlgorithm(cudnn_handle(),\n",
        "    //         l->weightDesc,\n",
        "    //         l->ddstTensorDesc,\n",
        "    //         l->convDesc,\n",
        "    //         l->dsrcTensorDesc,\n",
        "    //         (cudnnConvolutionBwdDataPreference_t)backward_algo,\n",
        "    //         workspace_size_specify,\n",
        "    //         &l->bd_algo));\n",
        "    // CHECK_CUDNN(cudnnGetConvolutionBackwardFilterAlgorithm(cudnn_handle(),\n",
        "    //         l->srcTensorDesc,\n",
        "    //         l->ddstTensorDesc,\n",
        "    //         l->convDesc,\n",
        "    //         l->dweightDesc,\n",
        "    //         (cudnnConvolutionBwdFilterPreference_t)backward_filter,\n",
        "    //         workspace_size_specify,\n",
        "    //         &l->bf_algo));\n",
        "\n",
        "    //if (data_type == CUDNN_DATA_HALF)\n",
        "    {\n",
        "        // HALF-16 if(data_type == CUDNN_DATA_HALF)\n",
        "        l->fw_algo16 = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM;\n",
        "        l->bd_algo16 = CUDNN_CONVOLUTION_BWD_DATA_ALGO_1;\n",
        "        l->bf_algo16 = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_1;\n",
        "\n",
        "        // FLOAT-32 if(data_type == CUDNN_DATA_FLOAT)\n",
        "        //l->fw_algo16 = CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD_NONFUSED;\n",
        "        //l->bd_algo16 = CUDNN_CONVOLUTION_BWD_DATA_ALGO_WINOGRAD_NONFUSED;\n",
        "        //l->bf_algo16 = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED;\n",
        "    }\n",
        "}\n",
        "#endif\n",
        "#endif\n",
        "\n",
        "\n",
        "void free_convolutional_batchnorm(convolutional_layer *l)\n",
        "{\n",
        "    if (!l->share_layer) {\n",
        "        if (l->scales)          free(l->scales),            l->scales = NULL;\n",
        "        if (l->scale_updates)   free(l->scale_updates),     l->scale_updates = NULL;\n",
        "        if (l->mean)            free(l->mean),              l->mean = NULL;\n",
        "        if (l->variance)        free(l->variance),          l->variance = NULL;\n",
        "        if (l->mean_delta)      free(l->mean_delta),        l->mean_delta = NULL;\n",
        "        if (l->variance_delta)  free(l->variance_delta),    l->variance_delta = NULL;\n",
        "        if (l->rolling_mean)    free(l->rolling_mean),      l->rolling_mean = NULL;\n",
        "        if (l->rolling_variance) free(l->rolling_variance),  l->rolling_variance = NULL;\n",
        "        if (l->x)               free(l->x),                 l->x = NULL;\n",
        "        if (l->x_norm)          free(l->x_norm),            l->x_norm = NULL;\n",
        "\n",
        "#ifdef GPU\n",
        "        if (l->scales_gpu)          cuda_free(l->scales_gpu),           l->scales_gpu = NULL;\n",
        "        if (l->scale_updates_gpu)   cuda_free(l->scale_updates_gpu),    l->scale_updates_gpu = NULL;\n",
        "        if (l->mean_gpu)            cuda_free(l->mean_gpu),             l->mean_gpu = NULL;\n",
        "        if (l->variance_gpu)        cuda_free(l->variance_gpu),         l->variance_gpu = NULL;\n",
        "        if (l->mean_delta_gpu)      cuda_free(l->mean_delta_gpu),       l->mean_delta_gpu = NULL;\n",
        "        if (l->variance_delta_gpu)  cuda_free(l->variance_delta_gpu),   l->variance_delta_gpu = NULL;\n",
        "        if (l->rolling_mean_gpu)    cuda_free(l->rolling_mean_gpu),     l->rolling_mean_gpu = NULL;\n",
        "        if (l->rolling_variance_gpu) cuda_free(l->rolling_variance_gpu), l->rolling_variance_gpu = NULL;\n",
        "        if (l->x_gpu)               cuda_free(l->x_gpu),                l->x_gpu = NULL;\n",
        "        if (l->x_norm_gpu)          cuda_free(l->x_norm_gpu),           l->x_norm_gpu = NULL;\n",
        "#endif\n",
        "    }\n",
        "}\n",
        "\n",
        "convolutional_layer make_convolutional_layer(int batch, int steps, int h, int w, int c, int n, int groups, int size, int stride_x, int stride_y, int dilation, int padding, ACTIVATION activation, int batch_normalize, int binary, int xnor, int adam, int use_bin_output, int index, int antialiasing, convolutional_layer *share_layer, int assisted_excitation, int deform, int train)\n",
        "{\n",
        "    int total_batch = batch*steps;\n",
        "    int i;\n",
        "    convolutional_layer l = { (LAYER_TYPE)0 };\n",
        "    l.type = CONVOLUTIONAL;\n",
        "    l.train = train;\n",
        "\n",
        "    if (xnor) groups = 1;   // disable groups for XNOR-net\n",
        "    if (groups < 1) groups = 1;\n",
        "\n",
        "    const int blur_stride_x = stride_x;\n",
        "    const int blur_stride_y = stride_y;\n",
        "    l.antialiasing = antialiasing;\n",
        "    if (antialiasing) {\n",
        "        stride_x = stride_y = l.stride = l.stride_x = l.stride_y = 1; // use stride=1 in host-layer\n",
        "    }\n",
        "\n",
        "    l.deform = deform;\n",
        "    l.assisted_excitation = assisted_excitation;\n",
        "    l.share_layer = share_layer;\n",
        "    l.index = index;\n",
        "    l.h = h;\n",
        "    l.w = w;\n",
        "    l.c = c;\n",
        "    l.groups = groups;\n",
        "    l.n = n;\n",
        "    l.binary = binary;\n",
        "    l.xnor = xnor;\n",
        "    l.use_bin_output = use_bin_output;\n",
        "    l.batch = batch;\n",
        "    l.steps = steps;\n",
        "    l.stride = stride_x;\n",
        "    l.stride_x = stride_x;\n",
        "    l.stride_y = stride_y;\n",
        "    l.dilation = dilation;\n",
        "    l.size = size;\n",
        "    l.pad = padding;\n",
        "    l.batch_normalize = batch_normalize;\n",
        "    l.learning_rate_scale = 1;\n",
        "    l.nweights = (c / groups) * n * size * size;\n",
        "\n",
        "    if (l.share_layer) {\n",
        "        if (l.size != l.share_layer->size || l.nweights != l.share_layer->nweights || l.c != l.share_layer->c || l.n != l.share_layer->n) {\n",
        "            printf(\" Layer size, nweights, channels or filters don't match for the share_layer\");\n",
        "            getchar();\n",
        "        }\n",
        "\n",
        "        l.weights = l.share_layer->weights;\n",
        "        l.weight_updates = l.share_layer->weight_updates;\n",
        "\n",
        "        l.biases = l.share_layer->biases;\n",
        "        l.bias_updates = l.share_layer->bias_updates;\n",
        "    }\n",
        "    else {\n",
        "        l.weights = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "        l.biases = (float*)xcalloc(n, sizeof(float));\n",
        "\n",
        "        if (train) {\n",
        "            l.weight_updates = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "            l.bias_updates = (float*)xcalloc(n, sizeof(float));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // float scale = 1./sqrt(size*size*c);\n",
        "    float scale = sqrt(2./(size*size*c/groups));\n",
        "    if (l.activation == NORM_CHAN || l.activation == NORM_CHAN_SOFTMAX || l.activation == NORM_CHAN_SOFTMAX_MAXVAL) {\n",
        "        for (i = 0; i < l.nweights; ++i) l.weights[i] = 1;   // rand_normal();\n",
        "    }\n",
        "    else {\n",
        "        for (i = 0; i < l.nweights; ++i) l.weights[i] = scale*rand_uniform(-1, 1);   // rand_normal();\n",
        "    }\n",
        "    int out_h = convolutional_out_height(l);\n",
        "    int out_w = convolutional_out_width(l);\n",
        "    l.out_h = out_h;\n",
        "    l.out_w = out_w;\n",
        "    l.out_c = n;\n",
        "    l.outputs = l.out_h * l.out_w * l.out_c;\n",
        "    l.inputs = l.w * l.h * l.c;\n",
        "    l.activation = activation;\n",
        "\n",
        "    l.output = (float*)xcalloc(total_batch*l.outputs, sizeof(float));\n",
        "#ifndef GPU\n",
        "    if (train) l.delta = (float*)xcalloc(total_batch*l.outputs, sizeof(float));\n",
        "#endif  // not GPU\n",
        "\n",
        "    l.forward = forward_convolutional_layer;\n",
        "    l.backward = backward_convolutional_layer;\n",
        "    l.update = update_convolutional_layer;\n",
        "    if(binary){\n",
        "        l.binary_weights = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "        l.cweights = (char*)xcalloc(l.nweights, sizeof(char));\n",
        "        l.scales = (float*)xcalloc(n, sizeof(float));\n",
        "    }\n",
        "    if(xnor){\n",
        "        l.binary_weights = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "        l.binary_input = (float*)xcalloc(l.inputs * l.batch, sizeof(float));\n",
        "\n",
        "        int align = 32;// 8;\n",
        "        int src_align = l.out_h*l.out_w;\n",
        "        l.bit_align = src_align + (align - src_align % align);\n",
        "\n",
        "        l.mean_arr = (float*)xcalloc(l.n, sizeof(float));\n",
        "\n",
        "        const size_t new_c = l.c / 32;\n",
        "        size_t in_re_packed_input_size = new_c * l.w * l.h + 1;\n",
        "        l.bin_re_packed_input = (uint32_t*)xcalloc(in_re_packed_input_size, sizeof(uint32_t));\n",
        "\n",
        "        l.lda_align = 256;  // AVX2\n",
        "        int k = l.size*l.size*l.c;\n",
        "        size_t k_aligned = k + (l.lda_align - k%l.lda_align);\n",
        "        size_t t_bit_input_size = k_aligned * l.bit_align / 8;\n",
        "        l.t_bit_input = (char*)xcalloc(t_bit_input_size, sizeof(char));\n",
        "    }\n",
        "\n",
        "    if(batch_normalize){\n",
        "        if (l.share_layer) {\n",
        "            l.scales = l.share_layer->scales;\n",
        "            l.scale_updates = l.share_layer->scale_updates;\n",
        "            l.mean = l.share_layer->mean;\n",
        "            l.variance = l.share_layer->variance;\n",
        "            l.mean_delta = l.share_layer->mean_delta;\n",
        "            l.variance_delta = l.share_layer->variance_delta;\n",
        "            l.rolling_mean = l.share_layer->rolling_mean;\n",
        "            l.rolling_variance = l.share_layer->rolling_variance;\n",
        "        }\n",
        "        else {\n",
        "            l.scales = (float*)xcalloc(n, sizeof(float));\n",
        "            for (i = 0; i < n; ++i) {\n",
        "                l.scales[i] = 1;\n",
        "            }\n",
        "            if (train) {\n",
        "                l.scale_updates = (float*)xcalloc(n, sizeof(float));\n",
        "\n",
        "                l.mean = (float*)xcalloc(n, sizeof(float));\n",
        "                l.variance = (float*)xcalloc(n, sizeof(float));\n",
        "\n",
        "                l.mean_delta = (float*)xcalloc(n, sizeof(float));\n",
        "                l.variance_delta = (float*)xcalloc(n, sizeof(float));\n",
        "            }\n",
        "            l.rolling_mean = (float*)xcalloc(n, sizeof(float));\n",
        "            l.rolling_variance = (float*)xcalloc(n, sizeof(float));\n",
        "        }\n",
        "\n",
        "#ifndef GPU\n",
        "        if (train) {\n",
        "            l.x = (float*)xcalloc(total_batch * l.outputs, sizeof(float));\n",
        "            l.x_norm = (float*)xcalloc(total_batch * l.outputs, sizeof(float));\n",
        "        }\n",
        "#endif  // not GPU\n",
        "    }\n",
        "\n",
        "#ifndef GPU\n",
        "    if (l.activation == SWISH || l.activation == MISH) l.activation_input = (float*)calloc(total_batch*l.outputs, sizeof(float));\n",
        "#endif  // not GPU\n",
        "\n",
        "    if(adam){\n",
        "        l.adam = 1;\n",
        "        l.m = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "        l.v = (float*)xcalloc(l.nweights, sizeof(float));\n",
        "        l.bias_m = (float*)xcalloc(n, sizeof(float));\n",
        "        l.scale_m = (float*)xcalloc(n, sizeof(float));\n",
        "        l.bias_v = (float*)xcalloc(n, sizeof(float));\n",
        "        l.scale_v = (float*)xcalloc(n, sizeof(float));\n",
        "    }\n",
        "\n",
        "#ifdef GPU\n",
        "\n",
        "\n",
        "    l.forward_gpu = forward_convolutional_layer_gpu;\n",
        "    l.backward_gpu = backward_convolutional_layer_gpu;\n",
        "    l.update_gpu = update_convolutional_layer_gpu;\n",
        "\n",
        "    if(gpu_index >= 0){\n",
        "\n",
        "        if (l.activation == SWISH || l.activation == MISH) {\n",
        "            l.activation_input_gpu = cuda_make_array(l.activation_input, total_batch*l.outputs);\n",
        "        }\n",
        "\n",
        "        if (l.deform) l.weight_deform_gpu = cuda_make_array(NULL, l.nweights);\n",
        "\n",
        "        if (adam) {\n",
        "            l.m_gpu = cuda_make_array(l.m, l.nweights);\n",
        "            l.v_gpu = cuda_make_array(l.v, l.nweights);\n",
        "            l.bias_m_gpu = cuda_make_array(l.bias_m, n);\n",
        "            l.bias_v_gpu = cuda_make_array(l.bias_v, n);\n",
        "            l.scale_m_gpu = cuda_make_array(l.scale_m, n);\n",
        "            l.scale_v_gpu = cuda_make_array(l.scale_v, n);\n",
        "        }\n",
        "        if (l.share_layer) {\n",
        "            l.weights_gpu = l.share_layer->weights_gpu;\n",
        "            l.weight_updates_gpu = l.share_layer->weight_updates_gpu;\n",
        "            l.weights_gpu16 = l.share_layer->weights_gpu16;\n",
        "            l.weight_updates_gpu16 = l.share_layer->weight_updates_gpu16;\n",
        "            l.biases_gpu = l.share_layer->biases_gpu;\n",
        "            l.bias_updates_gpu = l.share_layer->bias_updates_gpu;\n",
        "        }\n",
        "        else {\n",
        "            l.weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
        "            if (train) l.weight_updates_gpu = cuda_make_array(l.weight_updates, l.nweights);\n",
        "#ifdef CUDNN_HALF\n",
        "            l.weights_gpu16 = cuda_make_array(NULL, l.nweights / 2 + 1);\n",
        "            if (train) l.weight_updates_gpu16 = cuda_make_array(NULL, l.nweights / 2 + 1);\n",
        "#endif  // CUDNN_HALF\n",
        "            l.biases_gpu = cuda_make_array(l.biases, n);\n",
        "            if (train) l.bias_updates_gpu = cuda_make_array(l.bias_updates, n);\n",
        "        }\n",
        "\n",
        "        l.output_gpu = cuda_make_array(l.output, total_batch*out_h*out_w*n);\n",
        "        if (train) l.delta_gpu = cuda_make_array(l.delta, total_batch*out_h*out_w*n);\n",
        "\n",
        "        if(binary){\n",
        "            l.binary_weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
        "        }\n",
        "        if(xnor){\n",
        "            l.binary_weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
        "            l.mean_arr_gpu = cuda_make_array(0, l.n);\n",
        "            l.binary_input_gpu = cuda_make_array(0, l.inputs*l.batch);\n",
        "        }\n",
        "\n",
        "        if(batch_normalize){\n",
        "            if (l.share_layer) {\n",
        "                l.scales_gpu = l.share_layer->scales_gpu;\n",
        "                l.scale_updates_gpu = l.share_layer->scale_updates_gpu;\n",
        "                l.mean_gpu = l.share_layer->mean_gpu;\n",
        "                l.variance_gpu = l.share_layer->variance_gpu;\n",
        "                l.rolling_mean_gpu = l.share_layer->rolling_mean_gpu;\n",
        "                l.rolling_variance_gpu = l.share_layer->rolling_variance_gpu;\n",
        "                l.mean_delta_gpu = l.share_layer->mean_delta_gpu;\n",
        "                l.variance_delta_gpu = l.share_layer->variance_delta_gpu;\n",
        "            }\n",
        "            else {\n",
        "                l.scales_gpu = cuda_make_array(l.scales, n);\n",
        "\n",
        "                if (train) {\n",
        "                    l.scale_updates_gpu = cuda_make_array(l.scale_updates, n);\n",
        "\n",
        "                    l.mean_gpu = cuda_make_array(l.mean, n);\n",
        "                    l.variance_gpu = cuda_make_array(l.variance, n);\n",
        "                    l.m_cbn_avg_gpu = cuda_make_array(l.mean, n);\n",
        "                    l.v_cbn_avg_gpu = cuda_make_array(l.variance, n);\n",
        "#ifndef CUDNN\n",
        "                    l.mean_delta_gpu = cuda_make_array(l.mean, n);\n",
        "                    l.variance_delta_gpu = cuda_make_array(l.variance, n);\n",
        "#endif  // CUDNN\n",
        "                }\n",
        "\n",
        "                l.rolling_mean_gpu = cuda_make_array(l.mean, n);\n",
        "                l.rolling_variance_gpu = cuda_make_array(l.variance, n);\n",
        "            }\n",
        "\n",
        "            if (train) {\n",
        "                l.x_gpu = cuda_make_array(l.output, total_batch*out_h*out_w*n);\n",
        "#ifndef CUDNN\n",
        "                l.x_norm_gpu = cuda_make_array(l.output, total_batch*out_h*out_w*n);\n",
        "#endif  // CUDNN\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if (l.assisted_excitation)\n",
        "        {\n",
        "            const int size = l.out_w * l.out_h * l.batch;\n",
        "            l.gt_gpu = cuda_make_array(NULL, size);\n",
        "            l.a_avg_gpu = cuda_make_array(NULL, size);\n",
        "        }\n",
        "#ifdef CUDNN\n",
        "        create_convolutional_cudnn_tensors(&l);\n",
        "        cudnn_convolutional_setup(&l, cudnn_fastest, 0);\n",
        "#endif  // CUDNN\n",
        "    }\n",
        "#endif  // GPU\n",
        "    l.workspace_size = get_convolutional_workspace_size(l);\n",
        "\n",
        "    //fprintf(stderr, \"conv  %5d %2d x%2d /%2d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", n, size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
        "    l.bflops = (2.0 * l.nweights * l.out_h*l.out_w) / 1000000000.;\n",
        "    if (l.xnor) l.bflops = l.bflops / 32;\n",
        "    if (l.xnor && l.use_bin_output) fprintf(stderr, \"convXB\");\n",
        "    else if (l.xnor) fprintf(stderr, \"convX \");\n",
        "    else if (l.share_layer) fprintf(stderr, \"convS \");\n",
        "    else if (l.assisted_excitation) fprintf(stderr, \"convAE\");\n",
        "    else fprintf(stderr, \"conv  \");\n",
        "\n",
        "    if (groups > 1) fprintf(stderr, \"%5d/%4d \", n, groups);\n",
        "    else           fprintf(stderr, \"%5d      \", n);\n",
        "\n",
        "    if (stride_x != stride_y) fprintf(stderr, \"%2dx%2d/%2dx%2d \", size, size, stride_x, stride_y);\n",
        "    else {\n",
        "        if (dilation > 1) fprintf(stderr, \"%2d x%2d/%2d(%1d)\", size, size, stride_x, dilation);\n",
        "        else             fprintf(stderr, \"%2d x%2d/%2d   \", size, size, stride_x);\n",
        "    }\n",
        "\n",
        "    fprintf(stderr, \"%4d x%4d x%4d -> %4d x%4d x%4d %5.3f BF\\n\", w, h, c, l.out_w, l.out_h, l.out_c, l.bflops);\n",
        "\n",
        "    //fprintf(stderr, \"%5d/%2d %2d x%2d /%2d(%d)%4d x%4d x%4d  -> %4d x%4d x%4d %5.3f BF\\n\", n, groups, size, size, stride, dilation, w, h, c, l.out_w, l.out_h, l.out_c, l.bflops);\n",
        "\n",
        "    if (l.antialiasing) {\n",
        "        printf(\"AA:  \");\n",
        "        l.input_layer = (layer*)calloc(1, sizeof(layer));\n",
        "        int blur_size = 3;\n",
        "        int blur_pad = blur_size / 2;\n",
        "        if (l.antialiasing == 2) {\n",
        "            blur_size = 2;\n",
        "            blur_pad = 0;\n",
        "        }\n",
        "        *(l.input_layer) = make_convolutional_layer(batch, steps, out_h, out_w, n, n, n, blur_size, blur_stride_x, blur_stride_y, 1, blur_pad, LINEAR, 0, 0, 0, 0, 0, index, 0, NULL, 0, 0, train);\n",
        "        const int blur_nweights = n * blur_size * blur_size;  // (n / n) * n * blur_size * blur_size;\n",
        "        int i;\n",
        "        if (blur_size == 2) {\n",
        "            for (i = 0; i < blur_nweights; i += (blur_size*blur_size)) {\n",
        "                l.input_layer->weights[i + 0] = 1 / 4.f;\n",
        "                l.input_layer->weights[i + 1] = 1 / 4.f;\n",
        "                l.input_layer->weights[i + 2] = 1 / 4.f;\n",
        "                l.input_layer->weights[i + 3] = 1 / 4.f;\n",
        "            }\n",
        "        }\n",
        "        else {\n",
        "            for (i = 0; i < blur_nweights; i += (blur_size*blur_size)) {\n",
        "                l.input_layer->weights[i + 0] = 1 / 16.f;\n",
        "                l.input_layer->weights[i + 1] = 2 / 16.f;\n",
        "                l.input_layer->weights[i + 2] = 1 / 16.f;\n",
        "\n",
        "                l.input_layer->weights[i + 3] = 2 / 16.f;\n",
        "                l.input_layer->weights[i + 4] = 4 / 16.f;\n",
        "                l.input_layer->weights[i + 5] = 2 / 16.f;\n",
        "\n",
        "                l.input_layer->weights[i + 6] = 1 / 16.f;\n",
        "                l.input_layer->weights[i + 7] = 2 / 16.f;\n",
        "                l.input_layer->weights[i + 8] = 1 / 16.f;\n",
        "            }\n",
        "        }\n",
        "        for (i = 0; i < n; ++i) l.input_layer->biases[i] = 0;\n",
        "#ifdef GPU\n",
        "        if (gpu_index >= 0) {\n",
        "            l.input_antialiasing_gpu = cuda_make_array(NULL, l.batch*l.outputs);\n",
        "            push_convolutional_layer(*(l.input_layer));\n",
        "        }\n",
        "#endif  // GPU\n",
        "    }\n",
        "\n",
        "    return l;\n",
        "}\n",
        "\n",
        "void denormalize_convolutional_layer(convolutional_layer l)\n",
        "{\n",
        "    int i, j;\n",
        "    for(i = 0; i < l.n; ++i){\n",
        "        float scale = l.scales[i]/sqrt(l.rolling_variance[i] + .00001);\n",
        "        for(j = 0; j < l.nweights; ++j){\n",
        "            l.weights[i*l.nweights + j] *= scale;\n",
        "        }\n",
        "        l.biases[i] -= l.rolling_mean[i] * scale;\n",
        "        l.scales[i] = 1;\n",
        "        l.rolling_mean[i] = 0;\n",
        "        l.rolling_variance[i] = 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "void test_convolutional_layer()\n",
        "{\n",
        "    convolutional_layer l = make_convolutional_layer(1, 1, 5, 5, 3, 2, 1, 5, 2, 2, 1, 1, LEAKY, 1, 0, 0, 0, 0, 0, 0, NULL, 0, 0, 0);\n",
        "    l.batch_normalize = 1;\n",
        "    float data[] = {1,1,1,1,1,\n",
        "        1,1,1,1,1,\n",
        "        1,1,1,1,1,\n",
        "        1,1,1,1,1,\n",
        "        1,1,1,1,1,\n",
        "        2,2,2,2,2,\n",
        "        2,2,2,2,2,\n",
        "        2,2,2,2,2,\n",
        "        2,2,2,2,2,\n",
        "        2,2,2,2,2,\n",
        "        3,3,3,3,3,\n",
        "        3,3,3,3,3,\n",
        "        3,3,3,3,3,\n",
        "        3,3,3,3,3,\n",
        "        3,3,3,3,3};\n",
        "    network_state state = {0};\n",
        "    state.input = data;\n",
        "    forward_convolutional_layer(l, state);\n",
        "}\n",
        "\n",
        "void resize_convolutional_layer(convolutional_layer *l, int w, int h)\n",
        "{\n",
        "    int total_batch = l->batch*l->steps;\n",
        "    int old_w = l->w;\n",
        "    int old_h = l->h;\n",
        "    l->w = w;\n",
        "    l->h = h;\n",
        "    int out_w = convolutional_out_width(*l);\n",
        "    int out_h = convolutional_out_height(*l);\n",
        "\n",
        "    l->out_w = out_w;\n",
        "    l->out_h = out_h;\n",
        "\n",
        "    l->outputs = l->out_h * l->out_w * l->out_c;\n",
        "    l->inputs = l->w * l->h * l->c;\n",
        "\n",
        "\n",
        "    l->output = (float*)xrealloc(l->output, total_batch * l->outputs * sizeof(float));\n",
        "    if (l->train) {\n",
        "        l->delta = (float*)xrealloc(l->delta, total_batch * l->outputs * sizeof(float));\n",
        "\n",
        "        if (l->batch_normalize) {\n",
        "            l->x = (float*)xrealloc(l->x, total_batch * l->outputs * sizeof(float));\n",
        "            l->x_norm = (float*)xrealloc(l->x_norm, total_batch * l->outputs * sizeof(float));\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (l->xnor) {\n",
        "        //l->binary_input = realloc(l->inputs*l->batch, sizeof(float));\n",
        "    }\n",
        "\n",
        "    if (l->activation == SWISH || l->activation == MISH) l->activation_input = (float*)realloc(l->activation_input, total_batch*l->outputs * sizeof(float));\n",
        "#ifdef GPU\n",
        "    if (old_w < w || old_h < h || l->dynamic_minibatch) {\n",
        "        if (l->train) {\n",
        "            cuda_free(l->delta_gpu);\n",
        "            l->delta_gpu = cuda_make_array(l->delta, total_batch*l->outputs);\n",
        "        }\n",
        "\n",
        "        cuda_free(l->output_gpu);\n",
        "        l->output_gpu = cuda_make_array(l->output, total_batch*l->outputs);\n",
        "\n",
        "        if (l->batch_normalize) {\n",
        "            cuda_free(l->x_gpu);\n",
        "            l->x_gpu = cuda_make_array(l->output, total_batch*l->outputs);\n",
        "\n",
        "#ifndef CUDNN\n",
        "            cuda_free(l->x_norm_gpu);\n",
        "            l->x_norm_gpu = cuda_make_array(l->output, total_batch*l->outputs);\n",
        "#endif  // CUDNN\n",
        "        }\n",
        "\n",
        "        if (l->xnor) {\n",
        "            cuda_free(l->binary_input_gpu);\n",
        "            l->binary_input_gpu = cuda_make_array(0, l->inputs*l->batch);\n",
        "        }\n",
        "\n",
        "        if (l->activation == SWISH || l->activation == MISH) {\n",
        "            cuda_free(l->activation_input_gpu);\n",
        "            l->activation_input_gpu = cuda_make_array(l->activation_input, total_batch*l->outputs);\n",
        "        }\n",
        "\n",
        "        if (l->assisted_excitation)\n",
        "        {\n",
        "            cuda_free(l->gt_gpu);\n",
        "            cuda_free(l->a_avg_gpu);\n",
        "\n",
        "            const int size = l->out_w * l->out_h * l->batch;\n",
        "            l->gt_gpu = cuda_make_array(NULL, size);\n",
        "            l->a_avg_gpu = cuda_make_array(NULL, size);\n",
        "        }\n",
        "    }\n",
        "#ifdef CUDNN\n",
        "    cudnn_convolutional_setup(l, cudnn_fastest, 0);\n",
        "#endif\n",
        "#endif\n",
        "    l->workspace_size = get_convolutional_workspace_size(*l);\n",
        "\n",
        "#ifdef CUDNN\n",
        "    // check for excessive memory consumption\n",
        "    size_t free_byte;\n",
        "    size_t total_byte;\n",
        "    CHECK_CUDA(cudaMemGetInfo(&free_byte, &total_byte));\n",
        "    if (l->workspace_size > free_byte || l->workspace_size >= total_byte / 2) {\n",
        "        printf(\" used slow CUDNN algo without Workspace! Need memory: %zu, available: %zu\\n\", l->workspace_size, (free_byte < total_byte/2) ? free_byte : total_byte/2);\n",
        "        cudnn_convolutional_setup(l, cudnn_smallest, 0);\n",
        "        l->workspace_size = get_convolutional_workspace_size(*l);\n",
        "    }\n",
        "#endif\n",
        "}\n",
        "\n",
        "void set_specified_workspace_limit(convolutional_layer *l, size_t workspace_size_limit)\n",
        "{\n",
        "#ifdef CUDNN\n",
        "    size_t free_byte;\n",
        "    size_t total_byte;\n",
        "    CHECK_CUDA(cudaMemGetInfo(&free_byte, &total_byte));\n",
        "    cudnn_convolutional_setup(l, cudnn_specify, workspace_size_limit);\n",
        "    l->workspace_size = get_convolutional_workspace_size(*l);\n",
        "    //printf(\"Set specified workspace limit for cuDNN: %zu, available: %zu, workspace = %zu \\n\", workspace_size_limit, free_byte, l->workspace_size);\n",
        "#endif  // CUDNN\n",
        "}\n",
        "\n",
        "void add_bias(float *output, float *biases, int batch, int n, int size)\n",
        "{\n",
        "    int i,j,b;\n",
        "    for(b = 0; b < batch; ++b){\n",
        "        for(i = 0; i < n; ++i){\n",
        "            for(j = 0; j < size; ++j){\n",
        "                output[(b*n + i)*size + j] += biases[i];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void scale_bias(float *output, float *scales, int batch, int n, int size)\n",
        "{\n",
        "    int i,j,b;\n",
        "    for(b = 0; b < batch; ++b){\n",
        "        for(i = 0; i < n; ++i){\n",
        "            for(j = 0; j < size; ++j){\n",
        "                output[(b*n + i)*size + j] *= scales[i];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void backward_bias(float *bias_updates, float *delta, int batch, int n, int size)\n",
        "{\n",
        "    int i,b;\n",
        "    for(b = 0; b < batch; ++b){\n",
        "        for(i = 0; i < n; ++i){\n",
        "            bias_updates[i] += sum_array(delta+size*(i+b*n), size);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void gemm_nn_custom(int M, int N, int K, float ALPHA,\n",
        "    float *A, int lda,\n",
        "    float *B, int ldb,\n",
        "    float *C, int ldc)\n",
        "{\n",
        "    int i, j, k;\n",
        "    for (i = 0; i < M; ++i) {\n",
        "        for (k = 0; k < K; ++k) {\n",
        "            PUT_IN_REGISTER float A_PART = ALPHA * A[i * lda + k];\n",
        "            //printf(\"\\n weight = %f \\n\", A_PART);\n",
        "            for (j = 0; j < N; ++j) {\n",
        "                C[i*ldc + j] += A_PART*B[k*ldb + j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void get_mean_array(float *src, size_t size, size_t filters, float *mean_arr) {\n",
        "    size_t i, counter;\n",
        "    counter = 0;\n",
        "    for (i = 0; i < size; i += size / filters) {\n",
        "        mean_arr[counter++] = fabs(src[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "/*\n",
        "void float_to_bit(float *src, unsigned char *dst, size_t size) {\n",
        "\n",
        "    size_t dst_size = size / 8 + 1;\n",
        "    memset(dst, 0, dst_size);\n",
        "    size_t i, dst_i, dst_shift;\n",
        "    for (i = 0; i < size; ++i) {\n",
        "        if (src[i] > 0) set_bit(dst, i);\n",
        "    }\n",
        "}\n",
        "*/\n",
        "\n",
        "void bit_to_float(unsigned char *src, float *dst, size_t size, size_t filters, float *mean_arr) {\n",
        "    memset(dst, 0, size *sizeof(float));\n",
        "    size_t i;\n",
        "\n",
        "    for (i = 0; i < size; ++i) {\n",
        "        float mean_val = 1;\n",
        "        if(mean_arr != NULL) mean_val = fabs(mean_arr[i / (size / filters)]);\n",
        "        if(get_bit(src, i)) dst[i] = mean_val;\n",
        "        else dst[i] = -mean_val;\n",
        "    }\n",
        "}\n",
        "\n",
        "void binary_align_weights(convolutional_layer *l)\n",
        "{\n",
        "    int m = l->n;   // (l->n / l->groups)\n",
        "    int k = l->size*l->size*l->c;   // ->size*l->size*(l->c / l->groups)\n",
        "    size_t new_lda = k + (l->lda_align - k % l->lda_align); // (k / 8 + 1) * 8;\n",
        "    l->new_lda = new_lda;\n",
        "\n",
        "    binarize_weights(l->weights, m, k, l->binary_weights);\n",
        "\n",
        "    size_t align_weights_size = new_lda * m;\n",
        "    l->align_bit_weights_size = align_weights_size / 8 + 1;\n",
        "    float* align_weights = (float*)xcalloc(align_weights_size, sizeof(float));\n",
        "    l->align_bit_weights = (char*)xcalloc(l->align_bit_weights_size, sizeof(char));\n",
        "\n",
        "    size_t i, j;\n",
        "    // align A without transpose\n",
        "    for (i = 0; i < m; ++i) {\n",
        "        for (j = 0; j < k; ++j) {\n",
        "            align_weights[i*new_lda + j] = l->binary_weights[i*k + j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    if (l->c % 32 == 0)\n",
        "    //if(gpu_index < 0 && l->stride == 1 && l->pad == 1 && l->c % 32 == 0)\n",
        "    //if (l->stride == 1 && l->pad == 1 && l->c % 32 == 0)\n",
        "    {\n",
        "        int fil, chan;\n",
        "        const int items_per_filter = l->c * l->size * l->size;\n",
        "        //const int dst_items_per_filter = new_lda;\n",
        "        for (fil = 0; fil < l->n; ++fil)\n",
        "        {\n",
        "            for (chan = 0; chan < l->c; chan += 32)\n",
        "            {\n",
        "                const int items_per_channel = l->size*l->size;\n",
        "                for (i = 0; i < items_per_channel; ++i)\n",
        "                {\n",
        "                    //uint32_t val = 0;\n",
        "                    int c_pack;\n",
        "                    for (c_pack = 0; c_pack < 32; ++c_pack) {\n",
        "                        float src = l->binary_weights[fil*items_per_filter + (chan + c_pack)*items_per_channel + i];\n",
        "\n",
        "                        //align_weights[fil*items_per_filter + chan*items_per_channel + i * 32 + c_pack] = src;\n",
        "\n",
        "                        align_weights[fil*new_lda + chan*items_per_channel + i*32 + c_pack] = src;\n",
        "                        //val |= (src << c);\n",
        "                    }\n",
        "\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        //printf(\"\\n l.index = %d \\t aw[0] = %f, aw[1] = %f, aw[2] = %f, aw[3] = %f \\n\", l->index, align_weights[0], align_weights[1], align_weights[2], align_weights[3]);\n",
        "        //memcpy(l->binary_weights, align_weights, (l->size * l->size * l->c * l->n) * sizeof(float));\n",
        "\n",
        "        float_to_bit(align_weights, (unsigned char*)l->align_bit_weights, align_weights_size);\n",
        "\n",
        "        //if (l->n >= 32)\n",
        "        if(gpu_index >= 0)\n",
        "        {\n",
        "            //int M = l->n;\n",
        "            //int N = l->out_w*l->out_h;\n",
        "            //printf(\"\\n M = %d, N = %d, M %% 8 = %d, N %% 8 = %d - weights \\n\", M, N, M % 8, N % 8);\n",
        "            //printf(\"\\n l.w = %d, l.c = %d, l.n = %d \\n\", l->w, l->c, l->n);\n",
        "            for (i = 0; i < align_weights_size / 8; ++i) l->align_bit_weights[i] = ~(l->align_bit_weights[i]);\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        get_mean_array(l->binary_weights, m*k, l->n, l->mean_arr);\n",
        "        //get_mean_array(l->binary_weights, m*new_lda, l->n, l->mean_arr);\n",
        "    }\n",
        "    else {\n",
        "        float_to_bit(align_weights, (unsigned char*)l->align_bit_weights, align_weights_size);\n",
        "\n",
        "        get_mean_array(l->binary_weights, m*k, l->n, l->mean_arr);\n",
        "    }\n",
        "\n",
        "    //l->mean_arr = calloc(l->n, sizeof(float));\n",
        "\n",
        "    //get_mean_array(align_weights, align_weights_size, l->n, l->mean_arr);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ifdef GPU\n",
        "    cudaError_t status;\n",
        "    l->align_workspace_size = l->bit_align * l->size * l->size * l->c;\n",
        "    status = cudaMalloc((void **)&l->align_workspace_gpu, l->align_workspace_size * sizeof(float));\n",
        "    status = cudaMalloc((void **)&l->transposed_align_workspace_gpu, l->align_workspace_size * sizeof(float));\n",
        "    CHECK_CUDA(status);\n",
        "\n",
        "    //l->align_bit_weights_gpu = cuda_make_array(l->align_bit_weights, l->align_bit_weights_size * sizeof(char)/sizeof(float));\n",
        "    status = cudaMalloc((void **)&l->align_bit_weights_gpu, l->align_bit_weights_size);\n",
        "    CHECK_CUDA(status);\n",
        "    status = cudaMemcpy(l->align_bit_weights_gpu, l->align_bit_weights, l->align_bit_weights_size, cudaMemcpyHostToDevice);\n",
        "    CHECK_CUDA(status);\n",
        "    status = cudaMemcpy(l->binary_weights_gpu, l->binary_weights, m*k * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    CHECK_CUDA(status);\n",
        "\n",
        "    //l->mean_arr_gpu = cuda_make_array(l->mean_arr, l->n);\n",
        "    cuda_push_array(l->mean_arr_gpu, l->mean_arr, l->n);\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());\n",
        "#endif // GPU\n",
        "\n",
        "    free(align_weights);\n",
        "}\n",
        "\n",
        "// binary transpose\n",
        "size_t binary_transpose_align_input(int k, int n, float *b, char **t_bit_input, size_t ldb_align, int bit_align)\n",
        "{\n",
        "    size_t new_ldb = k + (ldb_align - k%ldb_align); // (k / 8 + 1) * 8;\n",
        "    //printf(\"\\n n = %d, bit_align = %d \\n\", n, bit_align);\n",
        "    size_t t_intput_size = new_ldb * bit_align;// n;\n",
        "    size_t t_bit_input_size = t_intput_size / 8;// +1;\n",
        "\n",
        "    memset(*t_bit_input, 0, t_bit_input_size * sizeof(char));\n",
        "    //int src_size = k * bit_align;\n",
        "\n",
        "    // b - [bit_align, k] - [l.bit_align, l.size*l.size*l.c] = src_size\n",
        "    // t_input - [bit_align, k] - [n', k]\n",
        "    // t_bit_input - [new_ldb, n] - [k', n]\n",
        "\n",
        "    //transpose_bin(t_input, *t_bit_input, k, n, bit_align, new_ldb, 8);\n",
        "    transpose_bin((uint32_t*)b, (uint32_t*)*t_bit_input, k, n, bit_align, new_ldb, 8);\n",
        "\n",
        "    return t_intput_size;\n",
        "}\n",
        "\n",
        "\n",
        "void forward_convolutional_layer(convolutional_layer l, network_state state)\n",
        "{\n",
        "    int out_h = convolutional_out_height(l);\n",
        "    int out_w = convolutional_out_width(l);\n",
        "    int i, j;\n",
        "\n",
        "    fill_cpu(l.outputs*l.batch, 0, l.output, 1);\n",
        "\n",
        "    if (l.xnor && (!l.align_bit_weights || state.train)) {\n",
        "        if (!l.align_bit_weights || state.train) {\n",
        "            binarize_weights(l.weights, l.n, l.nweights, l.binary_weights);\n",
        "            //printf(\"\\n binarize_weights l.align_bit_weights = %p \\n\", l.align_bit_weights);\n",
        "        }\n",
        "        swap_binary(&l);\n",
        "        binarize_cpu(state.input, l.c*l.h*l.w*l.batch, l.binary_input);\n",
        "        state.input = l.binary_input;\n",
        "    }\n",
        "\n",
        "    int m = l.n / l.groups;\n",
        "    int k = l.size*l.size*l.c / l.groups;\n",
        "    int n = out_h*out_w;\n",
        "\n",
        "    static int u = 0;\n",
        "    u++;\n",
        "\n",
        "    for(i = 0; i < l.batch; ++i)\n",
        "    {\n",
        "        for (j = 0; j < l.groups; ++j)\n",
        "        {\n",
        "            float *a = l.weights +j*l.nweights / l.groups;\n",
        "            float *b = state.workspace;\n",
        "            float *c = l.output +(i*l.groups + j)*n*m;\n",
        "\n",
        "            //gemm(0,0,m,n,k,1,a,k,b,n,1,c,n);\n",
        "            //gemm_nn_custom(m, n, k, 1, a, k, b, n, c, n);\n",
        "            if (l.xnor && l.align_bit_weights && !state.train && l.stride_x == l.stride_y)\n",
        "            {\n",
        "                memset(b, 0, l.bit_align*l.size*l.size*l.c * sizeof(float));\n",
        "\n",
        "                if (l.c % 32 == 0)\n",
        "                {\n",
        "                    //printf(\" l.index = %d - new XNOR \\n\", l.index);\n",
        "\n",
        "                    int ldb_align = l.lda_align;\n",
        "                    size_t new_ldb = k + (ldb_align - k%ldb_align); // (k / 8 + 1) * 8;\n",
        "                    //size_t t_intput_size = new_ldb * l.bit_align;// n;\n",
        "                    //size_t t_bit_input_size = t_intput_size / 8;// +1;\n",
        "\n",
        "                    int re_packed_input_size = l.c * l.w * l.h;\n",
        "                    memset(state.workspace, 0, re_packed_input_size * sizeof(float));\n",
        "\n",
        "                    const size_t new_c = l.c / 32;\n",
        "                    size_t in_re_packed_input_size = new_c * l.w * l.h + 1;\n",
        "                    memset(l.bin_re_packed_input, 0, in_re_packed_input_size * sizeof(uint32_t));\n",
        "\n",
        "                    //float *re_packed_input = calloc(l.c * l.w * l.h, sizeof(float));\n",
        "                    //uint32_t *bin_re_packed_input = calloc(new_c * l.w * l.h + 1, sizeof(uint32_t));\n",
        "\n",
        "                    // float32x4 by channel (as in cuDNN)\n",
        "                    repack_input(state.input, state.workspace, l.w, l.h, l.c);\n",
        "\n",
        "                    // 32 x floats -> 1 x uint32_t\n",
        "                    float_to_bit(state.workspace, (unsigned char *)l.bin_re_packed_input, l.c * l.w * l.h);\n",
        "\n",
        "                    //free(re_packed_input);\n",
        "\n",
        "                    // slow - convolution the packed inputs and weights: float x 32 by channel (as in cuDNN)\n",
        "                    //convolution_repacked((uint32_t *)bin_re_packed_input, (uint32_t *)l.align_bit_weights, l.output,\n",
        "                    //    l.w, l.h, l.c, l.n, l.size, l.pad, l.new_lda, l.mean_arr);\n",
        "\n",
        "                    // // then exit from if()\n",
        "\n",
        "\n",
        "                    im2col_cpu_custom((float *)l.bin_re_packed_input, new_c, l.h, l.w, l.size, l.stride, l.pad, state.workspace);\n",
        "                    //im2col_cpu((float *)bin_re_packed_input, new_c, l.h, l.w, l.size, l.stride, l.pad, b);\n",
        "\n",
        "                    //free(bin_re_packed_input);\n",
        "\n",
        "                    int new_k = l.size*l.size*l.c / 32;\n",
        "\n",
        "                    // good for (l.c == 64)\n",
        "                    //gemm_nn_bin_32bit_packed(m, n, new_k, 1,\n",
        "                    //    l.align_bit_weights, l.new_lda/32,\n",
        "                    //    b, n,\n",
        "                    //    c, n, l.mean_arr);\n",
        "\n",
        "    // // then exit from if()\n",
        "\n",
        "                    transpose_uint32((uint32_t *)state.workspace, (uint32_t*)l.t_bit_input, new_k, n, n, new_ldb);\n",
        "\n",
        "                    // the main GEMM function\n",
        "                    gemm_nn_custom_bin_mean_transposed(m, n, k, 1, (unsigned char*)l.align_bit_weights, new_ldb, (unsigned char*)l.t_bit_input, new_ldb, c, n, l.mean_arr);\n",
        "\n",
        "                    // // alternative GEMM\n",
        "                    //gemm_nn_bin_transposed_32bit_packed(m, n, new_k, 1,\n",
        "                    //    l.align_bit_weights, l.new_lda/32,\n",
        "                    //    t_bit_input, new_ldb / 32,\n",
        "                    //    c, n, l.mean_arr);\n",
        "\n",
        "                    //free(t_bit_input);\n",
        "\n",
        "                }\n",
        "                else\n",
        "                { // else (l.c % 32 != 0)\n",
        "\n",
        "                    //--------------------------------------------------------\n",
        "                    //printf(\" l.index = %d - old XNOR \\n\", l.index);\n",
        "\n",
        "                    //im2col_cpu_custom_align(state.input, l.c, l.h, l.w, l.size, l.stride, l.pad, b, l.bit_align);\n",
        "                    im2col_cpu_custom_bin(state.input, l.c, l.h, l.w, l.size, l.stride, l.pad, state.workspace, l.bit_align);\n",
        "\n",
        "                    //size_t output_size = l.outputs;\n",
        "                    //float *count_output = calloc(output_size, sizeof(float));\n",
        "                    //size_t bit_output_size = output_size / 8 + 1;\n",
        "                    //char *bit_output = calloc(bit_output_size, sizeof(char));\n",
        "\n",
        "                    //size_t intput_size = n * k; // (out_h*out_w) X (l.size*l.size*l.c) : after im2col()\n",
        "                    //size_t bit_input_size = intput_size / 8 + 1;\n",
        "                    //char *bit_input = calloc(bit_input_size, sizeof(char));\n",
        "\n",
        "                    //size_t weights_size = k * m; //l.size*l.size*l.c*l.n; // l.nweights\n",
        "                    //size_t bit_weights_size = weights_size / 8 + 1;\n",
        "\n",
        "                    //char *bit_weights = calloc(bit_weights_size, sizeof(char));\n",
        "                    //float *mean_arr = calloc(l.n, sizeof(float));\n",
        "\n",
        "                    // transpose B from NxK to KxN (x-axis (ldb = l.size*l.size*l.c) - should be multiple of 8 bits)\n",
        "                    {\n",
        "                        //size_t ldb_align = 256; // 256 bit for AVX2\n",
        "                        int ldb_align = l.lda_align;\n",
        "                        size_t new_ldb = k + (ldb_align - k%ldb_align);\n",
        "                        size_t t_intput_size = binary_transpose_align_input(k, n, state.workspace, &l.t_bit_input, ldb_align, l.bit_align);\n",
        "\n",
        "                        // 5x times faster than gemm()-float32\n",
        "                        gemm_nn_custom_bin_mean_transposed(m, n, k, 1, (unsigned char*)l.align_bit_weights, new_ldb, (unsigned char*)l.t_bit_input, new_ldb, c, n, l.mean_arr);\n",
        "\n",
        "                        //gemm_nn_custom_bin_mean_transposed(m, n, k, 1, bit_weights, k, t_bit_input, new_ldb, c, n, mean_arr);\n",
        "\n",
        "                        //free(t_input);\n",
        "                        //free(t_bit_input);\n",
        "                        //}\n",
        "                    }\n",
        "\n",
        "                }\n",
        "\n",
        "                add_bias(l.output, l.biases, l.batch, l.n, out_h*out_w);\n",
        "\n",
        "                //activate_array(l.output, m*n*l.batch, l.activation);\n",
        "                if (l.activation == SWISH) activate_array_swish(l.output, l.outputs*l.batch, l.activation_input, l.output);\n",
        "                else if (l.activation == MISH) activate_array_mish(l.output, l.outputs*l.batch, l.activation_input, l.output);\n",
        "                else if (l.activation == NORM_CHAN) activate_array_normalize_channels(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output);\n",
        "                else if (l.activation == NORM_CHAN_SOFTMAX) activate_array_normalize_channels_softmax(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, 0);\n",
        "                else if (l.activation == NORM_CHAN_SOFTMAX_MAXVAL) activate_array_normalize_channels_softmax(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, 1);\n",
        "                else activate_array_cpu_custom(l.output, m*n*l.batch, l.activation);\n",
        "                return;\n",
        "\n",
        "            }\n",
        "            else {\n",
        "                //printf(\" l.index = %d - FP32 \\n\", l.index);\n",
        "                float *im = state.input + (i*l.groups + j)*(l.c / l.groups)*l.h*l.w;\n",
        "                if (l.size == 1) {\n",
        "                    b = im;\n",
        "                }\n",
        "                else {\n",
        "                    //im2col_cpu(im, l.c / l.groups, l.h, l.w, l.size, l.stride, l.pad, b);\n",
        "\n",
        "                    im2col_cpu_ext(im,   // input\n",
        "                        l.c / l.groups,     // input channels\n",
        "                        l.h, l.w,           // input size (h, w)\n",
        "                        l.size, l.size,     // kernel size (h, w)\n",
        "                        l.pad * l.dilation, l.pad * l.dilation,       // padding (h, w)\n",
        "                        l.stride_y, l.stride_x, // stride (h, w)\n",
        "                        l.dilation, l.dilation, // dilation (h, w)\n",
        "                        b);                 // output\n",
        "\n",
        "                }\n",
        "\n",
        "                gemm(0, 0, m, n, k, 1, a, k, b, n, 1, c, n);\n",
        "                // bit-count to float\n",
        "            }\n",
        "            //c += n*m;\n",
        "            //state.input += l.c*l.h*l.w;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(l.batch_normalize){\n",
        "        forward_batchnorm_layer(l, state);\n",
        "    }\n",
        "    else {\n",
        "        add_bias(l.output, l.biases, l.batch, l.n, out_h*out_w);\n",
        "    }\n",
        "\n",
        "    //activate_array(l.output, m*n*l.batch, l.activation);\n",
        "    if (l.activation == SWISH) activate_array_swish(l.output, l.outputs*l.batch, l.activation_input, l.output);\n",
        "    else if (l.activation == MISH) activate_array_mish(l.output, l.outputs*l.batch, l.activation_input, l.output);\n",
        "    else if (l.activation == NORM_CHAN) activate_array_normalize_channels(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output);\n",
        "    else if (l.activation == NORM_CHAN_SOFTMAX) activate_array_normalize_channels_softmax(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, 0);\n",
        "    else if (l.activation == NORM_CHAN_SOFTMAX_MAXVAL) activate_array_normalize_channels_softmax(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, 1);\n",
        "    else activate_array_cpu_custom(l.output, l.outputs*l.batch, l.activation);\n",
        "\n",
        "    if(l.binary || l.xnor) swap_binary(&l);\n",
        "\n",
        "    //visualize_convolutional_layer(l, \"conv_visual\", NULL);\n",
        "    //wait_until_press_key_cv();\n",
        "\n",
        "    if(l.assisted_excitation && state.train) assisted_excitation_forward(l, state);\n",
        "\n",
        "    if (l.antialiasing) {\n",
        "        network_state s = { 0 };\n",
        "        s.train = state.train;\n",
        "        s.workspace = state.workspace;\n",
        "        s.net = state.net;\n",
        "        s.input = l.output;\n",
        "        forward_convolutional_layer(*(l.input_layer), s);\n",
        "        //simple_copy_ongpu(l.outputs*l.batch, l.output, l.input_antialiasing);\n",
        "        memcpy(l.output, l.input_layer->output, l.input_layer->outputs * l.input_layer->batch * sizeof(float));\n",
        "    }\n",
        "}\n",
        "\n",
        "void assisted_excitation_forward(convolutional_layer l, network_state state)\n",
        "{\n",
        "    const int iteration_num = (*state.net.seen) / (state.net.batch*state.net.subdivisions);\n",
        "\n",
        "    // epoch\n",
        "    //const float epoch = (float)(*state.net.seen) / state.net.train_images_num;\n",
        "\n",
        "    // calculate alpha\n",
        "    //const float alpha = (1 + cos(3.141592 * iteration_num)) / (2 * state.net.max_batches);\n",
        "    //const float alpha = (1 + cos(3.141592 * epoch)) / (2 * state.net.max_batches);\n",
        "    float alpha = (1 + cos(3.141592 * iteration_num / state.net.max_batches));\n",
        "\n",
        "    if (l.assisted_excitation > 1) {\n",
        "        if (iteration_num > l.assisted_excitation) alpha = 0;\n",
        "        else alpha = (1 + cos(3.141592 * iteration_num / l.assisted_excitation));\n",
        "    }\n",
        "\n",
        "    //printf(\"\\n epoch = %f, alpha = %f, seen = %d, max_batches = %d, train_images_num = %d \\n\",\n",
        "    //    epoch, alpha, (*state.net.seen), state.net.max_batches, state.net.train_images_num);\n",
        "\n",
        "    float *a_avg = (float *)xcalloc(l.out_w * l.out_h * l.batch, sizeof(float));\n",
        "    float *g = (float *)xcalloc(l.out_w * l.out_h * l.batch, sizeof(float));\n",
        "\n",
        "    int b;\n",
        "    int w, h, c;\n",
        "\n",
        "    l.max_boxes = state.net.num_boxes;\n",
        "    l.truths = l.max_boxes*(4 + 1);\n",
        "\n",
        "    for (b = 0; b < l.batch; ++b)\n",
        "    {\n",
        "        // calculate G\n",
        "        int t;\n",
        "        for (t = 0; t < state.net.num_boxes; ++t) {\n",
        "            box truth = float_to_box_stride(state.truth + t*(4 + 1) + b*l.truths, 1);\n",
        "            if (!truth.x) break;  // continue;\n",
        "\n",
        "            int left = floor((truth.x - truth.w / 2) * l.out_w);\n",
        "            int right = ceil((truth.x + truth.w / 2) * l.out_w);\n",
        "            int top = floor((truth.y - truth.h / 2) * l.out_h);\n",
        "            int bottom = ceil((truth.y + truth.h / 2) * l.out_h);\n",
        "\n",
        "            for (w = left; w <= right; w++) {\n",
        "                for (h = top; h < bottom; h++) {\n",
        "                    g[w + l.out_w * h + l.out_w*l.out_h*b] = 1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (b = 0; b < l.batch; ++b)\n",
        "    {\n",
        "        // calculate average A\n",
        "        for (w = 0; w < l.out_w; w++) {\n",
        "            for (h = 0; h < l.out_h; h++) {\n",
        "                for (c = 0; c < l.out_c; c++) {\n",
        "                    a_avg[w + l.out_w*(h + l.out_h*b)] += l.output[w + l.out_w*(h + l.out_h*(c + l.out_c*b))];\n",
        "                }\n",
        "                a_avg[w + l.out_w*(h + l.out_h*b)] /= l.out_c;  // a_avg / d\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // change activation\n",
        "    for (b = 0; b < l.batch; ++b)\n",
        "    {\n",
        "        for (w = 0; w < l.out_w; w++) {\n",
        "            for (h = 0; h < l.out_h; h++) {\n",
        "                for (c = 0; c < l.out_c; c++)\n",
        "                {\n",
        "                    // a = a + alpha(t) + e(c,i,j) = a + alpha(t) + g(i,j) * avg_a(i,j) / channels\n",
        "                    l.output[w + l.out_w*(h + l.out_h*(c + l.out_c*b))] +=\n",
        "                        alpha *\n",
        "                        g[w + l.out_w*(h + l.out_h*b)] *\n",
        "                        a_avg[w + l.out_w*(h + l.out_h*b)];\n",
        "\n",
        "                    //l.output[w + l.out_w*(h + l.out_h*(c + l.out_c*b))] =\n",
        "                    //    alpha * g[w + l.out_w*(h + l.out_h*b)] * a_avg[w + l.out_w*(h + l.out_h*b)];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(0)   // visualize ground truth\n",
        "    {\n",
        "#ifdef OPENCV\n",
        "        for (b = 0; b < l.batch; ++b)\n",
        "        {\n",
        "            image img = float_to_image(l.out_w, l.out_h, 1, &g[l.out_w*l.out_h*b]);\n",
        "            char buff[100];\n",
        "            sprintf(buff, \"a_excitation_%d\", b);\n",
        "            show_image_cv(img, buff);\n",
        "\n",
        "            image img2 = float_to_image(l.out_w, l.out_h, 1, &l.output[l.out_w*l.out_h*l.out_c*b]);\n",
        "            char buff2[100];\n",
        "            sprintf(buff2, \"a_excitation_act_%d\", b);\n",
        "            show_image_cv(img2, buff2);\n",
        "            wait_key_cv(5);\n",
        "        }\n",
        "        wait_until_press_key_cv();\n",
        "#endif // OPENCV\n",
        "    }\n",
        "\n",
        "    free(g);\n",
        "    free(a_avg);\n",
        "}\n",
        "\n",
        "\n",
        "void backward_convolutional_layer(convolutional_layer l, network_state state)\n",
        "{\n",
        "    int i, j;\n",
        "    int m = l.n / l.groups;\n",
        "    int n = l.size*l.size*l.c / l.groups;\n",
        "    int k = l.out_w*l.out_h;\n",
        "\n",
        "    if (l.activation == SWISH) gradient_array_swish(l.output, l.outputs*l.batch, l.activation_input, l.delta);\n",
        "    else if (l.activation == MISH) gradient_array_mish(l.outputs*l.batch, l.activation_input, l.delta);\n",
        "    else if (l.activation == NORM_CHAN_SOFTMAX || l.activation == NORM_CHAN_SOFTMAX_MAXVAL) gradient_array_normalize_channels_softmax(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.delta);\n",
        "    else if (l.activation == NORM_CHAN) gradient_array_normalize_channels(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.delta);\n",
        "    else gradient_array(l.output, l.outputs*l.batch, l.activation, l.delta);\n",
        "\n",
        "    if (l.batch_normalize) {\n",
        "        backward_batchnorm_layer(l, state);\n",
        "    }\n",
        "    else {\n",
        "        backward_bias(l.bias_updates, l.delta, l.batch, l.n, k);\n",
        "    }\n",
        "\n",
        "    for (i = 0; i < l.batch; ++i) {\n",
        "        for (j = 0; j < l.groups; ++j) {\n",
        "            float *a = l.delta + (i*l.groups + j)*m*k;\n",
        "            float *b = state.workspace;\n",
        "            float *c = l.weight_updates + j*l.nweights / l.groups;\n",
        "\n",
        "            float *im = state.input + (i*l.groups + j)* (l.c / l.groups)*l.h*l.w;\n",
        "\n",
        "            //im2col_cpu(im, l.c / l.groups, l.h, l.w, l.size, l.stride, l.pad, b);\n",
        "            im2col_cpu_ext(\n",
        "                im,                 // input\n",
        "                l.c / l.groups,     // input channels\n",
        "                l.h, l.w,           // input size (h, w)\n",
        "                l.size, l.size,     // kernel size (h, w)\n",
        "                l.pad * l.dilation, l.pad * l.dilation,       // padding (h, w)\n",
        "                l.stride_y, l.stride_x, // stride (h, w)\n",
        "                l.dilation, l.dilation, // dilation (h, w)\n",
        "                b);                 // output\n",
        "\n",
        "            gemm(0, 1, m, n, k, 1, a, k, b, k, 1, c, n);\n",
        "\n",
        "            if (state.delta) {\n",
        "                a = l.weights + j*l.nweights / l.groups;\n",
        "                b = l.delta + (i*l.groups + j)*m*k;\n",
        "                c = state.workspace;\n",
        "\n",
        "                gemm(1, 0, n, k, m, 1, a, n, b, k, 0, c, k);\n",
        "\n",
        "                //col2im_cpu(state.workspace, l.c / l.groups, l.h, l.w, l.size, l.stride,\n",
        "                //     l.pad, state.delta + (i*l.groups + j)*l.c / l.groups*l.h*l.w);\n",
        "\n",
        "                col2im_cpu_ext(\n",
        "                    state.workspace,        // input\n",
        "                    l.c / l.groups,         // input channels (h, w)\n",
        "                    l.h, l.w,               // input size (h, w)\n",
        "                    l.size, l.size,         // kernel size (h, w)\n",
        "                    l.pad * l.dilation, l.pad * l.dilation,           // padding (h, w)\n",
        "                    l.stride_y, l.stride_x,     // stride (h, w)\n",
        "                    l.dilation, l.dilation, // dilation (h, w)\n",
        "                    state.delta + (i*l.groups + j)* (l.c / l.groups)*l.h*l.w); // output (delta)\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void update_convolutional_layer(convolutional_layer l, int batch, float learning_rate_init, float momentum, float decay)\n",
        "{\n",
        "    float learning_rate = learning_rate_init*l.learning_rate_scale;\n",
        "    //float momentum = a.momentum;\n",
        "    //float decay = a.decay;\n",
        "    //int batch = a.batch;\n",
        "\n",
        "    axpy_cpu(l.nweights, -decay*batch, l.weights, 1, l.weight_updates, 1);\n",
        "    axpy_cpu(l.nweights, learning_rate / batch, l.weight_updates, 1, l.weights, 1);\n",
        "    scal_cpu(l.nweights, momentum, l.weight_updates, 1);\n",
        "\n",
        "    axpy_cpu(l.n, learning_rate / batch, l.bias_updates, 1, l.biases, 1);\n",
        "    scal_cpu(l.n, momentum, l.bias_updates, 1);\n",
        "\n",
        "    if (l.scales) {\n",
        "        axpy_cpu(l.n, learning_rate / batch, l.scale_updates, 1, l.scales, 1);\n",
        "        scal_cpu(l.n, momentum, l.scale_updates, 1);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "image get_convolutional_weight(convolutional_layer l, int i)\n",
        "{\n",
        "    int h = l.size;\n",
        "    int w = l.size;\n",
        "    int c = l.c / l.groups;\n",
        "    return float_to_image(w, h, c, l.weights + i*h*w*c);\n",
        "}\n",
        "\n",
        "void rgbgr_weights(convolutional_layer l)\n",
        "{\n",
        "    int i;\n",
        "    for (i = 0; i < l.n; ++i) {\n",
        "        image im = get_convolutional_weight(l, i);\n",
        "        if (im.c == 3) {\n",
        "            rgbgr_image(im);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void rescale_weights(convolutional_layer l, float scale, float trans)\n",
        "{\n",
        "    int i;\n",
        "    for (i = 0; i < l.n; ++i) {\n",
        "        image im = get_convolutional_weight(l, i);\n",
        "        if (im.c == 3) {\n",
        "            scale_image(im, scale);\n",
        "            float sum = sum_array(im.data, im.w*im.h*im.c);\n",
        "            l.biases[i] += sum*trans;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "image *get_weights(convolutional_layer l)\n",
        "{\n",
        "    image *weights = (image *)xcalloc(l.n, sizeof(image));\n",
        "    int i;\n",
        "    for (i = 0; i < l.n; ++i) {\n",
        "        weights[i] = copy_image(get_convolutional_weight(l, i));\n",
        "        normalize_image(weights[i]);\n",
        "        /*\n",
        "        char buff[256];\n",
        "        sprintf(buff, \"filter%d\", i);\n",
        "        save_image(weights[i], buff);\n",
        "        */\n",
        "    }\n",
        "    //error(\"hey\");\n",
        "    return weights;\n",
        "}\n",
        "\n",
        "image *visualize_convolutional_layer(convolutional_layer l, char *window, image *prev_weights)\n",
        "{\n",
        "    image *single_weights = get_weights(l);\n",
        "    show_images(single_weights, l.n, window);\n",
        "\n",
        "    image delta = get_convolutional_image(l);\n",
        "    image dc = collapse_image_layers(delta, 1);\n",
        "    char buff[256];\n",
        "    sprintf(buff, \"%s: Output\", window);\n",
        "    show_image(dc, buff);\n",
        "    //save_image(dc, buff);\n",
        "    free_image(dc);\n",
        "    return single_weights;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "jMUhFuAD5nQd",
        "outputId": "bfe41ff3-2dcc-4a7f-a7fd-c2750afea271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing convolutional_layer.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos Makefile"
      ],
      "metadata": {
        "id": "MJaJOXtp7cpU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6dTiq5ga0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b4064f-84ea-433f-fe8b-89a6f62f5c02"
      },
      "source": [
        "%cd /content/darknet/\n",
        "%rm Makefile"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#colab occasionally shifts dependencies around, at the time of authorship, this Makefile works for building Darknet on Colab # PABLO\n",
        "\n",
        "%%writefile Makefile\n",
        "GPU=1\n",
        "CUDNN=1\n",
        "CUDNN_HALF=0\n",
        "OPENCV=1\n",
        "AVX=0\n",
        "OPENMP=0\n",
        "LIBSO=1\n",
        "ZED_CAMERA=0\n",
        "ZED_CAMERA_v2_8=0\n",
        "\n",
        "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
        "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n",
        "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
        "# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n",
        "# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n",
        "\n",
        "USE_CPP=0\n",
        "DEBUG=0\n",
        "\n",
        "ARCH= -gencode arch=compute_35,code=sm_35 \\\n",
        "      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
        "      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
        "\t    -gencode arch=compute_61,code=[sm_61,compute_61] \\\n",
        "      -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "ARCH= -gencode arch=compute_60,code=sm_60\n",
        "ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
        "\n",
        "OS := $(shell uname)\n",
        "\n",
        "VPATH=./src/\n",
        "EXEC=darknet\n",
        "OBJDIR=./obj/\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "LIBNAMESO=libdarknet.so\n",
        "APPNAMESO=uselib\n",
        "endif\n",
        "\n",
        "ifeq ($(USE_CPP), 1)\n",
        "CC=g++\n",
        "else\n",
        "CC=gcc\n",
        "endif\n",
        "\n",
        "CPP=g++ -std=c++11\n",
        "NVCC=nvcc\n",
        "OPTS=-Ofast\n",
        "LDFLAGS= -lm -pthread\n",
        "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
        "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC --param=fp_contract=off\n",
        "\n",
        "ifeq ($(DEBUG), 1)\n",
        "#OPTS= -O0 -g\n",
        "#OPTS= -Og -g\n",
        "COMMON+= -DDEBUG\n",
        "CFLAGS+= -DDEBUG\n",
        "else\n",
        "ifeq ($(AVX), 1)\n",
        "CFLAGS+= -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
        "endif\n",
        "endif\n",
        "\n",
        "CFLAGS+=$(OPTS)\n",
        "\n",
        "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
        "LDFLAGS+=-lws2_32\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENCV), 1)\n",
        "COMMON+= -DOPENCV\n",
        "CFLAGS+= -DOPENCV\n",
        "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
        "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENMP), 1)\n",
        "CFLAGS+= -fopenmp\n",
        "LDFLAGS+= -lgomp\n",
        "endif\n",
        "\n",
        "ifeq ($(GPU), 1)\n",
        "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
        "CFLAGS+= -DGPU\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN), 1)\n",
        "COMMON+= -DCUDNN\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
        "else\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
        "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN_HALF), 1)\n",
        "COMMON+= -DCUDNN_HALF\n",
        "CFLAGS+= -DCUDNN_HALF\n",
        "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "endif\n",
        "\n",
        "ifeq ($(ZED_CAMERA), 1)\n",
        "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
        "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "endif\n",
        "endif\n",
        "\n",
        "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
        "ifeq ($(GPU), 1)\n",
        "LDFLAGS+= -lstdc++\n",
        "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
        "endif\n",
        "\n",
        "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
        "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
        "\n",
        "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "CFLAGS+= -fPIC\n",
        "\n",
        "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
        "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
        "\n",
        "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
        "endif\n",
        "\n",
        "$(EXEC): $(OBJS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
        "\n",
        "$(OBJDIR)%.o: %.c $(DEPS)\n",
        "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cu $(DEPS)\n",
        "\t$(NVCC) $(ARCH) $(COMMON) -DGPU $(CFLAGS) --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -fPIC\" -c $< -o $@\n",
        "\n",
        "$(OBJDIR):\n",
        "\tmkdir -p $(OBJDIR)\n",
        "backup:\n",
        "\tmkdir -p backup\n",
        "results:\n",
        "\tmkdir -p results\n",
        "setchmod:\n",
        "\tchmod +x *.sh\n",
        "\n",
        ".PHONY: clean\n",
        "\n",
        "clean:\n",
        "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)"
      ],
      "metadata": {
        "id": "76ru3JhfLrdy",
        "outputId": "56575cfc-2cb2-4f87-c30c-139764e64d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyTAyEhOgd__"
      },
      "source": [
        "# OLD\n",
        "#colab occasionally shifts dependencies around, at the time of authorship, this Makefile works for building Darknet on Colab\n",
        "\n",
        "%%writefile Makefile\n",
        "GPU=1\n",
        "CUDNN=1\n",
        "CUDNN_HALF=0\n",
        "OPENCV=1\n",
        "AVX=0\n",
        "OPENMP=0\n",
        "LIBSO=1\n",
        "ZED_CAMERA=0\n",
        "ZED_CAMERA_v2_8=0\n",
        "\n",
        "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
        "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) GPU: Volta, Xavier, Turing and higher\n",
        "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
        "# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n",
        "# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n",
        "\n",
        "USE_CPP=0\n",
        "DEBUG=0\n",
        "\n",
        "ARCH= -gencode arch=compute_35,code=sm_35 \\\n",
        "      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
        "      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
        "\t    -gencode arch=compute_61,code=[sm_61,compute_61] \\\n",
        "      -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "OS := $(shell uname)\n",
        "\n",
        "VPATH=./src/\n",
        "EXEC=darknet\n",
        "OBJDIR=./obj/\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "LIBNAMESO=libdarknet.so\n",
        "APPNAMESO=uselib\n",
        "endif\n",
        "\n",
        "ifeq ($(USE_CPP), 1)\n",
        "CC=g++\n",
        "else\n",
        "CC=gcc\n",
        "endif\n",
        "\n",
        "CPP=g++ -std=c++11\n",
        "NVCC=nvcc\n",
        "OPTS=-Ofast\n",
        "LDFLAGS= -lm -pthread\n",
        "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
        "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n",
        "\n",
        "ifeq ($(DEBUG), 1)\n",
        "#OPTS= -O0 -g\n",
        "#OPTS= -Og -g\n",
        "COMMON+= -DDEBUG\n",
        "CFLAGS+= -DDEBUG\n",
        "else\n",
        "ifeq ($(AVX), 1)\n",
        "CFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
        "endif\n",
        "endif\n",
        "\n",
        "CFLAGS+=$(OPTS)\n",
        "\n",
        "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
        "LDFLAGS+=-lws2_32\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENCV), 1)\n",
        "COMMON+= -DOPENCV\n",
        "CFLAGS+= -DOPENCV\n",
        "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
        "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENMP), 1)\n",
        "CFLAGS+= -fopenmp\n",
        "LDFLAGS+= -lgomp\n",
        "endif\n",
        "\n",
        "ifeq ($(GPU), 1)\n",
        "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
        "CFLAGS+= -DGPU\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN), 1)\n",
        "COMMON+= -DCUDNN\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
        "else\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
        "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN_HALF), 1)\n",
        "COMMON+= -DCUDNN_HALF\n",
        "CFLAGS+= -DCUDNN_HALF\n",
        "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "endif\n",
        "\n",
        "ifeq ($(ZED_CAMERA), 1)\n",
        "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
        "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "endif\n",
        "endif\n",
        "\n",
        "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
        "ifeq ($(GPU), 1)\n",
        "LDFLAGS+= -lstdc++\n",
        "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
        "endif\n",
        "\n",
        "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
        "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
        "\n",
        "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "CFLAGS+= -fPIC\n",
        "\n",
        "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
        "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
        "\n",
        "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
        "endif\n",
        "\n",
        "$(EXEC): $(OBJS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
        "\n",
        "$(OBJDIR)%.o: %.c $(DEPS)\n",
        "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cu $(DEPS)\n",
        "\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n",
        "\n",
        "$(OBJDIR):\n",
        "\tmkdir -p $(OBJDIR)\n",
        "backup:\n",
        "\tmkdir -p backup\n",
        "results:\n",
        "\tmkdir -p results\n",
        "setchmod:\n",
        "\tchmod +x *.sh\n",
        "\n",
        ".PHONY: clean\n",
        "\n",
        "clean:\n",
        "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMBDkaL-Aep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60730080-3c36-46a4-d8c8-2134d9ec27dd"
      },
      "source": [
        "#install environment from the Makefile\n",
        "#note if you are on Colab Pro this works on a P100 GPU\n",
        "#if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "#this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "#note the Makefile above should work for you, if you need to tweak, try the below\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!make"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "mkdir -p ./obj/\n",
            "mkdir -p backup\n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC --param=fp_contract=off -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -fPIC -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "\u001b[01m\u001b[Kg++:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kunrecognized command-line option \u001b[01m\u001b[K--param=fp_contract=off\u001b[m\u001b[K; did you mean \u001b[01m\u001b[K--fp-contract=off\u001b[m\u001b[K?\n",
            "make: *** [Makefile:148: obj/image_opencv.o] Error 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGPDEjfAALrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12afdfe-18c4-49ef-82f5-fde8b9df8b81"
      },
      "source": [
        "#download the newly released yolov4 ConvNet weights\n",
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "--2024-03-05 17:51:52--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T175152Z&X-Amz-Expires=300&X-Amz-Signature=b9ccb78cb44a67e4904f322468e487c06048ff7a75e55d0a95975a777ff09c3b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-05 17:51:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/48bfe500-889d-11ea-819e-c4d182fcf0db?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240305T175152Z&X-Amz-Expires=300&X-Amz-Signature=b9ccb78cb44a67e4904f322468e487c06048ff7a75e55d0a95975a777ff09c3b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.conv.137&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170038676 (162M) [application/octet-stream]\n",
            "Saving to: yolov4.conv.137\n",
            "\n",
            "yolov4.conv.137     100%[===================>] 162.16M   192MB/s    in 0.8s    \n",
            "\n",
            "2024-03-05 17:51:53 (192 MB/s) - yolov4.conv.137 saved [170038676/170038676]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "# Set up Custom Dataset for YOLOv4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbniFj-eSimL"
      },
      "source": [
        "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format.\n",
        "\n",
        "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
        "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
        "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
        "4. Export your dataset in the **YOLO Darknet format**.\n",
        "5. Copy your download link, and paste it below.\n",
        "\n",
        "See our [blog post](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) for greater detail.\n",
        "\n",
        "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiQvussOcXdJ",
        "outputId": "ebc229be-ffa7-414f-b221-3f1e7bb1ef7e"
      },
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"dSQ1tDZXPuiUfMj9dJ8X\")\n",
        "project = rf.workspace(\"tfgworkspace-38k4o\").project(\"topologias\")\n",
        "dataset = project.version(1).download(\"darknet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.21)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in topologias-1 to darknet:: 100%|| 4023/4023 [00:00<00:00, 4650.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to topologias-1 in darknet:: 100%|| 360/360 [00:00<00:00, 6661.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cwW1B9kFfnmk",
        "outputId": "d0fb2072-34f1-407d-8ce3-73105c5db225"
      },
      "source": [
        "dataset.location"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/topologias-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCILEbs1NII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358388aa-491f-4050-f2fa-a4e81219a750"
      },
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd /content/darknet/\n",
        "%cp {dataset.location}/train/_darknet.labels data/obj.names\n",
        "%mkdir data/obj\n",
        "#copy image and labels\n",
        "%cp {dataset.location}/train/*.jpg data/obj/\n",
        "%cp {dataset.location}/valid/*.jpg data/obj/\n",
        "\n",
        "%cp {dataset.location}/train/*.txt data/obj/\n",
        "%cp {dataset.location}/valid/*.txt data/obj/\n",
        "\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "# Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WJcqHhpeVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88489b63-7d43-45af-cecd-a35fbdeb5d3f"
      },
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len(dataset.location + '/train/_darknet.labels')\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
        "\n",
        "\n",
        "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
        "  f.write('[net]' + '\\n')\n",
        "  f.write('batch=64' + '\\n')\n",
        "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
        "  f.write('subdivisions=24' + '\\n')\n",
        "  f.write('width=416' + '\\n')\n",
        "  f.write('height=416' + '\\n')\n",
        "  f.write('channels=3' + '\\n')\n",
        "  f.write('momentum=0.949' + '\\n')\n",
        "  f.write('decay=0.0005' + '\\n')\n",
        "  f.write('angle=0' + '\\n')\n",
        "  f.write('saturation = 1.5' + '\\n')\n",
        "  f.write('exposure = 1.5' + '\\n')\n",
        "  f.write('hue = .1' + '\\n')\n",
        "  f.write('\\n')\n",
        "  f.write('learning_rate=0.001' + '\\n')\n",
        "  f.write('burn_in=1000' + '\\n')\n",
        "  ######you can adjust up and down to change training time#####\n",
        "  ##Darknet does iterations with batches, not epochs####\n",
        "  # max_batches = num_classes*2000\n",
        "  max_batches = 2000 #PABLO\n",
        "  # max_batches = 8000\n",
        "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
        "  f.write('policy=steps' + '\\n')\n",
        "  steps1 = .8 * max_batches\n",
        "  steps2 = .9 * max_batches\n",
        "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
        "#change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        "\n",
        "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
        "    content = f2.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 0,1,2' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
        "    content = f3.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 3,4,5' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
        "    content = f4.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 6,7,8' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
        "    content = f5.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "\n",
        "print(\"file is written!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing config for a custom YOLOv4 detector detecting number of classes: 4\n",
            "file is written!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LAciMh4Cut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c4572d-43cd-475f-83b4-6dbd4e06968d"
      },
      "source": [
        "#here is the file that was just written.\n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-detector.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[net]\n",
            "batch=64\n",
            "subdivisions=24\n",
            "width=416\n",
            "height=416\n",
            "channels=3\n",
            "momentum=0.949\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue = .1\n",
            "\n",
            "learning_rate=0.001\n",
            "burn_in=1000\n",
            "max_batches=2000\n",
            "policy=steps\n",
            "steps=1600.0,1800.0\n",
            "scales=.1,.1\n",
            "\n",
            "#cutmix=1\n",
            "mosaic=1\n",
            "\n",
            "#:104x104 54:52x52 85:26x26 104:13x13 for 416\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -1,-7\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -1,-10\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -1,-28\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -1,-28\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "[route]\n",
            "layers = -1,-16\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=mish\n",
            "\n",
            "##########################\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "### SPP ###\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=5\n",
            "\n",
            "[route]\n",
            "layers=-2\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=9\n",
            "\n",
            "[route]\n",
            "layers=-4\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=13\n",
            "\n",
            "[route]\n",
            "layers=-1,-3,-5,-6\n",
            "### End SPP ###\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 85\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 54\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "##########################\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=27\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 0,1,2\n",
            "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
            "classes=4\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "scale_x_y = 1.2\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "max_delta=5\n",
            "\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=256\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1, -16\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=27\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
            "classes=4\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "scale_x_y = 1.1\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "max_delta=5\n",
            "\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=512\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1, -37\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=1024\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=27\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 6,7,8\n",
            "anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401\n",
            "classes=4\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "max_delta=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "# Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "QBnbaUx_D6zu",
        "outputId": "20a221b4-085c-4b06-d67f-a3f6d0b56db2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3rdparty      cfg\t\t      data\t\t     Makefile\t    src\n",
            "appveyor.yml  cmake\t\t      image_yolov2.sh\t     net_cam_v3.sh  video_v2.sh\n",
            "backup\t      CMakeLists.txt\t      image_yolov3.sh\t     obj\t    video_yolov3.sh\n",
            "build\t      DarknetConfig.cmake.in  include\t\t     README.md\t    yolov4.conv.137\n",
            "build.ps1     darknet.py\t      json_mjpeg_streams.sh  results\n",
            "build.sh      darknet_video.py\t      LICENSE\t\t     scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet.py detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ],
      "metadata": {
        "id": "IewSFnvEDuLS",
        "outputId": "cdacb19c-52c1-4a8f-9d14-3fd0057dd42c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./darknet.py: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYFbvExqMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebc415c-ca2e-4db7-9757-9d4a280be721"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./darknet: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "# Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dJB6NZv4kh"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKzw2TvZrOQ",
        "outputId": "de07fa2f-f5ac-457d-c391-5855b775a775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "#/test has images that we can test our detector on\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = \"test/\" + random.choice(test_images);\n",
        "\n",
        "#test out our detector!\n",
        "!./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_final.weights {img_path} -dont-show\n",
        "imShow('/content/darknet/predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7832a241a16e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#/test has images that we can test our detector on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test'"
          ]
        }
      ]
    }
  ]
}