{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloezquerroo/TFG/blob/main/Maquina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5R9wWQxMjCR",
        "outputId": "550f1917-1975-48b7-c135-3bc96b408635"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator #preproceso de imagentes\n",
        "from keras import optimizers #optimizador para el algoritmo\n",
        "from keras.models import Sequential #redes neuronales secuenciales\n",
        "from keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from keras.layers import  Convolution2D, MaxPooling2D\n",
        "from keras import backend as K #si hay una sesion keras en background la mata\n",
        "import os"
      ],
      "metadata": {
        "id": "zPyQvDuFNSJB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "data_entrenamiento= '/content/drive/MyDrive/TFG/Imágenes/Entrenamiento'\n",
        "data_validacion= '/content/drive/MyDrive/TFG/Imágenes/Validacion'\n",
        "\n",
        "def listar_contenido_directorio(ruta):\n",
        "    for root, dirs, files in os.walk(ruta):\n",
        "        print(f\"Directorio: {root}\")\n",
        "        print(f\"Subdirectorios: {dirs}\")\n",
        "        print(f\"Archivos: {files}\")\n",
        "\n",
        "listar_contenido_directorio(data_entrenamiento)\n",
        "listar_contenido_directorio(data_validacion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYOxgUybPpsY",
        "outputId": "5e62bdf7-f71b-4b92-e3ac-699c16288f8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Entrenamiento\n",
            "Subdirectorios: ['Router', 'DNS', 'Link', 'Switch']\n",
            "Archivos: []\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Entrenamiento/Router\n",
            "Subdirectorios: []\n",
            "Archivos: ['r (19).png', 'r (13).png', 'r (12).png', 'r (6).png', 'r (5).png', 'r (7).png', 'r (9).png', 'r (10).png', 'r (11).png', 'r (4).png', 'r (8).png', 'r (2).png', 'r (14).png', 'r (15).png', 'r (18).png', 'r (3).png', 'r (1).png', 'r (16).png', 'r (17).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Entrenamiento/DNS\n",
            "Subdirectorios: []\n",
            "Archivos: ['d (12).png', 'd (13).png', 'd (11).png', 'd (5).png', 'd (4).png', 'd (7).png', 'd (8).png', 'd (10).png', 'd (6).png', 'd (9).png', 'd (2).png', 'd (3).png', 'd (1).png', 'd (21).png', 'd (20).png', 'd (22).png', 'd (14).png', 'd (18).png', 'd (16).png', 'd (17).png', 'd (15).png', 'd (19).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Entrenamiento/Link\n",
            "Subdirectorios: []\n",
            "Archivos: ['l (16).png', 'l (8).png', 'l (7).png', 'l (19).png', 'l (2).png', 'l (4).png', 'l (5).png', 'l (1).png', 'l (18).png', 'l (3).png', 'l (6).png', 'l (17).png', 'l (9).png', 'l (14).png', 'l (15).png', 'l (11).png', 'l (12).png', 'l (10).png', 'l (13).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Entrenamiento/Switch\n",
            "Subdirectorios: []\n",
            "Archivos: ['s (9).png', 's (6).png', 's (8).png', 's (22).png', 's (1).png', 's (3).png', 's (2).png', 's (5).png', 's (7).png', 's (4).png', 's (20).png', 's (21).png', 's (19).png', 's (17).png', 's (16).png', 's (15).png', 's (18).png', 's (13).png', 's (10).png', 's (12).png', 's (11).png', 's (14).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Validacion\n",
            "Subdirectorios: ['Router', 'DNS', 'Link', 'Switch']\n",
            "Archivos: []\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Validacion/Router\n",
            "Subdirectorios: []\n",
            "Archivos: ['r (3).png', 'r (2).png', 'r (4).png', 'r (1).png', 'r (5).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Validacion/DNS\n",
            "Subdirectorios: []\n",
            "Archivos: ['d (5).png', 'd (3).png', 'd (6).png', 'd (2).png', 'd (7).png', 'd (1).png', 'd (8).png', 'd (4).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Validacion/Link\n",
            "Subdirectorios: []\n",
            "Archivos: ['l (23).png', 'l (24).png', 'l (22).png', 'l (21).png', 'l (20).png']\n",
            "Directorio: /content/drive/MyDrive/TFG/Imágenes/Validacion/Switch\n",
            "Subdirectorios: []\n",
            "Archivos: ['s (26).png', 's (24).png', 's (25).png', 's (30).png', 's (28).png', 's (27).png', 's (29).png', 's (23).png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros\n",
        "\n",
        "epocas = 20 # numero de iteraciones en el set de datos\n",
        "altura, longitud= 100, 100 # tamaño al que procesamos las imágenes\n",
        "batch_size_entrenamiento = 82 # numero de imagenes a procesar\n",
        "batch_size_validacion = 26 # numero de imagenes a procesar\n",
        "pasos = 1 # numero de pasos en cada una de las epocas\n",
        "pasos_validacion = 1 # numero de pasos al final de las epocas\n",
        "filtrosConv1 = 32 # numero de filtros\n",
        "filtrosConv2 = 64 # numero de filtros\n",
        "filtrosConv3 = 64 # numero de filtros\n",
        "tamano_filtro1 =(3,3)\n",
        "tamano_filtro2 =(3,3)\n",
        "tamano_filtro3 =(3,3)\n",
        "tamano_pool = (2,2)\n",
        "clases = 4 # tipos de salidas\n",
        "lr = 0.0005 # como de grande van a ser los ajustes para acercarse a la solucion optima\n",
        "\n",
        "# pre-procesamiento de imagenes\n",
        "\n",
        "entrenamiento_datagen= ImageDataGenerator(\n",
        "    rescale=1./255, # reescalamos de 0 a 1 los pixeles\n",
        "    shear_range=0.3, # algunas de las imagenes las inclina\n",
        "    zoom_range=0.3, # alguinas de las imagenes las amplia\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "validacion_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")\n",
        "\n",
        "imagen_entrenamiento = entrenamiento_datagen.flow_from_directory(\n",
        "    data_entrenamiento,\n",
        "    target_size= (altura, longitud),\n",
        "    batch_size=batch_size_entrenamiento,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "\n",
        "imagen_validacion = validacion_datagen.flow_from_directory(\n",
        "    data_validacion,\n",
        "    target_size= (altura, longitud),\n",
        "    batch_size=batch_size_validacion,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5xaYlUhQJJ0",
        "outputId": "85b8c66b-92d6-4cff-df57-d0c51a990ef9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 82 images belonging to 4 classes.\n",
            "Found 26 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la red convolucional\n",
        "\n",
        "cnn = Sequential()\n",
        "\n",
        "# Primera capa\n",
        "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding= 'same', input_shape=(altura, longitud, 1), activation='relu'))\n",
        "\n",
        "# Segunda capa\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "# Tercera capa\n",
        "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding= 'same', activation='relu'))\n",
        "\n",
        "# Cuarta capa\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "# Quinta capa\n",
        "cnn.add(Convolution2D(filtrosConv3, tamano_filtro3, padding= 'same', activation='relu'))\n",
        "\n",
        "# Sexta capa\n",
        "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n",
        "\n",
        "cnn.add(Flatten()) # La imagen que tenemos profunda la hacemos plana, 1 dimension con toda la informacion\n",
        "cnn.add(Dense(256, activation='relu')) # La imagen plana se la pasamos a una nueva capa en la que todas las neuronas estan conectadas a las de la anterior\n",
        "cnn.add(Dropout(0.5)) # En cada paso de entrenamiento apagamos la mitad de las neuronas a la capa densa para evitar sobreajustar.\n",
        "cnn.add(Dense(clases, activation='softmax')) # Capa final para clasificar\n",
        "\n",
        "# Durante el entrenamiento la funcion de perdida va a ser categorical crossentropy\n",
        "# Optimizador Adam\n",
        "# Metrica de porcentaje para saber como de bien esta aprendiendo la red\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=lr), metrics=['accuracy'])\n",
        "\n",
        "# Entrenamos la red con la imagen de entrenamiento, cada epoca tiene 1000 pasos, 20 epocas.\n",
        "# Despues de cada epoca va a correr 200 pasos de validacion\n",
        "history = cnn.fit(\n",
        "    imagen_entrenamiento,\n",
        "    steps_per_epoch=pasos,\n",
        "    epochs=epocas,\n",
        "    validation_data=imagen_validacion,\n",
        "    validation_steps=pasos_validacion\n",
        "    )\n",
        "\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "# model.save('/content/drive/MyDrive/TFG/mi_modelo.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10nzt22GUCkU",
        "outputId": "2db2b4ff-e59b-4807-c0b1-2c506c339427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.3975 - accuracy: 0.1951 - val_loss: 1.3660 - val_accuracy: 0.3846\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3923 - accuracy: 0.3537 - val_loss: 1.3549 - val_accuracy: 0.3077\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3681 - accuracy: 0.2927 - val_loss: 1.3629 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3551 - accuracy: 0.2805 - val_loss: 1.3724 - val_accuracy: 0.1923\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.3964 - accuracy: 0.2561 - val_loss: 1.3604 - val_accuracy: 0.3846\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3566 - accuracy: 0.3415 - val_loss: 1.3466 - val_accuracy: 0.3077\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3702 - accuracy: 0.2805 - val_loss: 1.3364 - val_accuracy: 0.3077\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3734 - accuracy: 0.2561 - val_loss: 1.3298 - val_accuracy: 0.3077\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3602 - accuracy: 0.3171 - val_loss: 1.3198 - val_accuracy: 0.3846\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.3617 - accuracy: 0.3293 - val_loss: 1.3073 - val_accuracy: 0.5385\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.3427 - accuracy: 0.4390 - val_loss: 1.2911 - val_accuracy: 0.6154\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3554 - accuracy: 0.3537 - val_loss: 1.2764 - val_accuracy: 0.6154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Paso 1: Calcular la precisión en datos de validación\n",
        "validation_loss, validation_accuracy = cnn.evaluate(imagen_validacion)\n",
        "print(f'Precisión en datos de validación: {validation_accuracy}')\n",
        "\n",
        "# Paso 2: Graficar la curva de aprendizaje\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Pérdida en conjunto de entrenamiento\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='validation')\n",
        "    plt.title('Pérdida en Entrenamiento vs. Validación')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.legend()\n",
        "\n",
        "    # Precisión en conjunto de entrenamiento\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='validation')\n",
        "    plt.title('Precisión en Entrenamiento vs. Validación')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisión')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_learning_curve(history)\n",
        "\n",
        "# Paso 3: Realizar predicciones en datos de validación\n",
        "y_pred = cnn.predict(imagen_validacion)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Paso 4: Matriz de Confusión\n",
        "confusion = confusion_matrix(imagen_validacion.classes, y_pred_classes)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(confusion)\n",
        "\n",
        "# Paso 5: Informe de Clasificación\n",
        "class_labels = list(imagen_validacion.class_indices.keys())\n",
        "print(\"Informe de Clasificación:\")\n",
        "print(classification_report(imagen_validacion.classes, y_pred_classes, target_names=class_labels))\n"
      ],
      "metadata": {
        "id": "Z0G2RnaRQ3sy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}